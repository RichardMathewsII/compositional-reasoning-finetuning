{"cells":[{"cell_type":"markdown","metadata":{"id":"fA4ROD7HaSJL"},"source":["## Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35892,"status":"ok","timestamp":1709318317993,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":360},"id":"LK63fBfDbM5D","outputId":"d8ddcccc-5054-458f-aaf8-43598ea45320"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.2)\n","Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n","Collecting loguru\n","  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: loguru\n","Successfully installed loguru-0.7.2\n","Collecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.25.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.2)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=30ff928f3b8d6c15179eaa9e5451aa1825b0707a8cf2cfba8c978fea3d98f588\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge-score\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.1.2\n","Collecting peft\n","  Downloading peft-0.9.0-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.38.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n","Collecting accelerate>=0.21.0 (from peft)\n","  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.2)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Installing collected packages: accelerate, peft\n","Successfully installed accelerate-0.27.2 peft-0.9.0\n"]}],"source":["# !pip install pytest\n","!pip install transformers\n","!pip install sentencepiece\n","!pip install tokenizers\n","!pip install nltk\n","!pip install loguru\n","!pip install rouge-score\n","!pip install peft"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"fO0ZlSt6vUQr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709318318196,"user_tz":360,"elapsed":207,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"}},"outputId":"b6f00658-e0ce-4305-fe92-7c63d0e62e00"},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"markdown","metadata":{"id":"mMShMWVHvT-r"},"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20174,"status":"ok","timestamp":1709318338344,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":360},"id":"1djF5RoWXDce","outputId":"26967d66-748c-4df5-b4a9-cb90bf879948"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":349,"status":"ok","timestamp":1709318338687,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":360},"id":"Hp1iPONkluJM","outputId":"8c5094ac-91a3-4936-9436-29c817e6648e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/projects/compositional-reasoning-finetuning\n"]}],"source":["%cd drive/MyDrive/projects/compositional-reasoning-finetuning"]},{"cell_type":"markdown","metadata":{"id":"EHxz0wAdNimM"},"source":["# Run Evaluation"]},{"cell_type":"markdown","source":["self-ask, no examplars, no answer first, no random facts"],"metadata":{"id":"sFhxO_zQSNrO"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"NkK2EtL9NhtG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709318364651,"user_tz":360,"elapsed":25989,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"}},"outputId":"4c7add3f-cbf0-4402-ebd2-f3e47d2fc200"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-01 18:39:01.979073: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-01 18:39:01.979135: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-01 18:39:01.980362: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-01 18:39:01.989109: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-03-01 18:39:03.715555: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[32m2024-03-01 18:39:14.220\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m570\u001b[0m - \u001b[34m\u001b[1mExamplars parameter -> False\u001b[0m\n","\u001b[32m2024-03-01 18:39:14.221\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m571\u001b[0m - \u001b[34m\u001b[1mCheckpoint loader parameter -> False\u001b[0m\n","\u001b[32m2024-03-01 18:39:14.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_set_t5_tokenizer\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mLoading tokenizer t5-small with max length of 300\u001b[0m\n","tokenizer_config.json: 100% 2.32k/2.32k [00:00<00:00, 10.6MB/s]\n","spiece.model: 100% 792k/792k [00:00<00:00, 3.01MB/s]\n","tokenizer.json: 100% 1.39M/1.39M [00:00<00:00, 4.18MB/s]\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","\u001b[32m2024-03-01 18:39:15.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m577\u001b[0m - \u001b[1mTest set pointing to file: data/MultihopEvaluation/self_ask-answer_first=False-random_facts=False-without-examplars.json\u001b[0m\n","\u001b[32m2024-03-01 18:39:15.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m578\u001b[0m - \u001b[1mResponses will be saved to: results/t5-small-self_ask-answer_first=False-random_facts=False-without-examplars-responses.json\u001b[0m\n","\u001b[32m2024-03-01 18:39:15.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m579\u001b[0m - \u001b[1mResults will be saved to: results/t5-small-self_ask-answer_first=False-random_facts=False-without-examplars-results.json\u001b[0m\n","\u001b[32m2024-03-01 18:39:18.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mLoading t5-small model\u001b[0m\n","config.json: 100% 1.21k/1.21k [00:00<00:00, 5.32MB/s]\n","model.safetensors: 100% 242M/242M [00:00<00:00, 255MB/s]\n","All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n","\n","All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/projects/compositional-reasoning-finetuning/evaluation.py\", line 592, in <module>\n","    model = load_model(config)\n","  File \"/content/drive/MyDrive/projects/compositional-reasoning-finetuning/evaluation.py\", line 190, in load_model\n","    keras_model = build_t5_training_wrapper_model(t5_model, max_length=max_length)\n","  File \"/content/drive/MyDrive/projects/compositional-reasoning-finetuning/training_utils.py\", line 147, in build_t5_training_wrapper_model\n","    t5_logits = t5_model(input_ids, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids)[0]\n","  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\", line 70, in error_handler\n","    raise e.with_traceback(filtered_tb) from None\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 428, in run_call_with_unpacked_inputs\n","    return func(self, **unpacked_inputs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 1446, in call\n","    encoder_outputs = self.encoder(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 428, in run_call_with_unpacked_inputs\n","    return func(self, **unpacked_inputs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 767, in call\n","    check_embeddings_within_bounds(input_ids, self.embed_tokens.input_dim)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/tf_utils.py\", line 163, in check_embeddings_within_bounds\n","    tf.debugging.assert_less(\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/tf_op_layer.py\", line 119, in handle\n","    return TFOpLambda(op)(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n","    raise e.with_traceback(filtered_tb) from None\n","TypeError: Exception encountered when calling layer 'encoder' (type TFT5MainLayer).\n","\n","Could not build a TypeSpec for name: \"tf.debugging.assert_less/assert_less/Assert/Assert\"\n","op: \"Assert\"\n","input: \"tf.debugging.assert_less/assert_less/All\"\n","input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_0\"\n","input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_1\"\n","input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_2\"\n","input: \"Placeholder\"\n","input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_4\"\n","input: \"tf.debugging.assert_less/assert_less/y\"\n","attr {\n","  key: \"T\"\n","  value {\n","    list {\n","      type: DT_STRING\n","      type: DT_STRING\n","      type: DT_STRING\n","      type: DT_INT32\n","      type: DT_STRING\n","      type: DT_INT32\n","    }\n","  }\n","}\n","attr {\n","  key: \"summarize\"\n","  value {\n","    i: 3\n","  }\n","}\n"," of unsupported type <class 'tensorflow.python.framework.ops.Operation'>.\n","\n","Call arguments received by layer 'encoder' (type TFT5MainLayer):\n","  • input_ids=<KerasTensor: shape=(None, 300) dtype=int32 (created by layer 'input_ids')>\n","  • attention_mask=<KerasTensor: shape=(None, 300) dtype=int32 (created by layer 'attention_mask')>\n","  • encoder_hidden_states=None\n","  • encoder_attention_mask=None\n","  • inputs_embeds=None\n","  • head_mask=None\n","  • encoder_head_mask=None\n","  • past_key_values=None\n","  • use_cache=None\n","  • output_attentions=False\n","  • output_hidden_states=False\n","  • return_dict=True\n","  • training=False\n"]}],"source":["!python3 evaluation.py --model='t5-small' --strategy='self_ask' --no-examplars --no-answer_first --no-random_facts --no-load_checkpoint  --size=-1"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"pcNmrUYBxZgb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709318085085,"user_tz":360,"elapsed":10760,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"}},"outputId":"1f480090-0f52-4b46-9fc5-0843a9ef66ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-01 18:34:35.106983: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-01 18:34:35.107031: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-01 18:34:35.108372: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-01 18:34:35.115570: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-03-01 18:34:36.159559: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[32m2024-03-01 18:34:41.809\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m570\u001b[0m - \u001b[34m\u001b[1mExamplars parameter -> True\u001b[0m\n","\u001b[32m2024-03-01 18:34:41.810\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m571\u001b[0m - \u001b[34m\u001b[1mCheckpoint loader parameter -> False\u001b[0m\n","\u001b[32m2024-03-01 18:34:41.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_set_t5_tokenizer\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mLoading tokenizer t5-small with max length of 300\u001b[0m\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","\u001b[32m2024-03-01 18:34:42.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m577\u001b[0m - \u001b[1mTest set pointing to file: data/MultihopEvaluation/self_ask-answer_first=False-random_facts=False-with-examplars.json\u001b[0m\n","\u001b[32m2024-03-01 18:34:42.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m578\u001b[0m - \u001b[1mResponses will be saved to: results/t5-small-self_ask-answer_first=False-random_facts=False-with-examplars-responses.json\u001b[0m\n","\u001b[32m2024-03-01 18:34:42.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m579\u001b[0m - \u001b[1mResults will be saved to: results/t5-small-self_ask-answer_first=False-random_facts=False-with-examplars-results.json\u001b[0m\n","\u001b[32m2024-03-01 18:34:42.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mLoading t5-small model\u001b[0m\n","2024-03-01 18:34:42.575273: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.582883: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.583139: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.583822: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.584082: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.584278: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.767624: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.767915: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.768055: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2024-03-01 18:34:42.768136: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.768281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n","\n","All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/projects/compositional-reasoning-finetuning/evaluation.py\", line 592, in <module>\n","    model = load_model(config)\n","  File \"/content/drive/MyDrive/projects/compositional-reasoning-finetuning/evaluation.py\", line 190, in load_model\n","    keras_model = build_t5_training_wrapper_model(t5_model, max_length=max_length)\n","  File \"/content/drive/MyDrive/projects/compositional-reasoning-finetuning/training_utils.py\", line 147, in build_t5_training_wrapper_model\n","    t5_logits = t5_model(input_ids, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids)[0]\n","  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\", line 70, in error_handler\n","    raise e.with_traceback(filtered_tb) from None\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 428, in run_call_with_unpacked_inputs\n","    return func(self, **unpacked_inputs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 1446, in call\n","    encoder_outputs = self.encoder(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 428, in run_call_with_unpacked_inputs\n","    return func(self, **unpacked_inputs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 767, in call\n","    check_embeddings_within_bounds(input_ids, self.embed_tokens.input_dim)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/tf_utils.py\", line 163, in check_embeddings_within_bounds\n","    tf.debugging.assert_less(\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/tf_op_layer.py\", line 119, in handle\n","    return TFOpLambda(op)(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n","    raise e.with_traceback(filtered_tb) from None\n","TypeError: Exception encountered when calling layer 'encoder' (type TFT5MainLayer).\n","\n","Could not build a TypeSpec for name: \"tf.debugging.assert_less/assert_less/Assert/Assert\"\n","op: \"Assert\"\n","input: \"tf.debugging.assert_less/assert_less/All\"\n","input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_0\"\n","input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_1\"\n","input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_2\"\n","input: \"Placeholder\"\n","input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_4\"\n","input: \"tf.debugging.assert_less/assert_less/y\"\n","attr {\n","  key: \"T\"\n","  value {\n","    list {\n","      type: DT_STRING\n","      type: DT_STRING\n","      type: DT_STRING\n","      type: DT_INT32\n","      type: DT_STRING\n","      type: DT_INT32\n","    }\n","  }\n","}\n","attr {\n","  key: \"summarize\"\n","  value {\n","    i: 3\n","  }\n","}\n"," of unsupported type <class 'tensorflow.python.framework.ops.Operation'>.\n","\n","Call arguments received by layer 'encoder' (type TFT5MainLayer):\n","  • input_ids=<KerasTensor: shape=(None, 300) dtype=int32 (created by layer 'input_ids')>\n","  • attention_mask=<KerasTensor: shape=(None, 300) dtype=int32 (created by layer 'attention_mask')>\n","  • encoder_hidden_states=None\n","  • encoder_attention_mask=None\n","  • inputs_embeds=None\n","  • head_mask=None\n","  • encoder_head_mask=None\n","  • past_key_values=None\n","  • use_cache=None\n","  • output_attentions=False\n","  • output_hidden_states=False\n","  • return_dict=True\n","  • training=False\n"]}],"source":["!python3 evaluation.py --model='t5-small' --strategy='self_ask' --examplars --no-answer_first --no-random_facts --no-load_checkpoint  --size=-1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CchiGgv1_TsV"},"outputs":[],"source":["!python3 evaluation.py --model='t5-small' --strategy='self_ask' --examplars --answer_first --no-random_facts --no-load_checkpoint  --size=-1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X5XUo2gVO2MQ"},"outputs":[],"source":["!python3 evaluation.py --model='t5-small' --strategy='self_ask' --no-examplars --answer_first --no-random_facts --no-load_checkpoint  --size=-1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YMyB_pFskH1z"},"outputs":[],"source":["!python3 evaluation.py --model='t5-small' --strategy='self_ask' --examplars --no-answer_first --random_facts --no-load_checkpoint  --size=-1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qyRfPM80xCSi"},"outputs":[],"source":["!python3 evaluation.py --model='t5-small' --strategy='self_ask' --no-examplars --no-answer_first --random_facts --no-load_checkpoint  --size=-1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mwXbuB2AqdXC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706470797867,"user_tz":360,"elapsed":36160,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"}},"outputId":"887aef0f-b14d-4001-9153-79e9266dea99"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-01-28 19:39:23.698816: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-01-28 19:39:23.698873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-01-28 19:39:23.700341: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-01-28 19:39:23.708366: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-01-28 19:39:26.324263: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[32m2024-01-28 19:39:38.570\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m543\u001b[0m - \u001b[34m\u001b[1mExamplars parameter -> False\u001b[0m\n","\u001b[32m2024-01-28 19:39:38.572\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m544\u001b[0m - \u001b[34m\u001b[1mCheckpoint loader parameter -> False\u001b[0m\n","\u001b[32m2024-01-28 19:39:38.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_set_t5_tokenizer\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mLoading tokenizer t5-small with max length of 300\u001b[0m\n","tokenizer_config.json: 100% 2.32k/2.32k [00:00<00:00, 9.17MB/s]\n","spiece.model: 100% 792k/792k [00:00<00:00, 10.6MB/s]\n","tokenizer.json: 100% 1.39M/1.39M [00:00<00:00, 11.9MB/s]\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","\u001b[32m2024-01-28 19:39:39.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m550\u001b[0m - \u001b[1mTest set pointing to file: data/MultihopEvaluation/direct-answer_first=False-random_facts=True-without-examplars.json\u001b[0m\n","\u001b[32m2024-01-28 19:39:39.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1mResponses will be saved to: results/t5-small-direct-answer_first=False-random_facts=True-without-examplars-responses.json\u001b[0m\n","\u001b[32m2024-01-28 19:39:39.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m552\u001b[0m - \u001b[1mResults will be saved to: results/t5-small-direct-answer_first=False-random_facts=True-without-examplars-results.json\u001b[0m\n","\u001b[32m2024-01-28 19:39:40.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m564\u001b[0m - \u001b[1mLoading t5-small model\u001b[0m\n","config.json: 100% 1.21k/1.21k [00:00<00:00, 5.81MB/s]\n","model.safetensors: 100% 242M/242M [00:01<00:00, 186MB/s]\n","2024-01-28 19:39:42.223993: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.518467: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.518880: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.519710: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.520019: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.520272: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.781261: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.781603: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.781823: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2024-01-28 19:39:42.781918: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.782144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n","\n","All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","\u001b[32m2024-01-28 19:39:54.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mLoading finetuned model weights from: models/t5-small-direct-answer_first=False-random_facts=True.h5\u001b[0m\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/projects/compositional-reasoning-finetuning/evaluation.py\", line 565, in <module>\n","    model = load_model(config)\n","  File \"/content/drive/MyDrive/projects/compositional-reasoning-finetuning/evaluation.py\", line 180, in load_model\n","    keras_model.load_weights(path)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n","    raise e.with_traceback(filtered_tb) from None\n","  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\", line 567, in __init__\n","    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n","  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\", line 231, in make_fid\n","    fid = h5f.open(name, flags, fapl=fapl)\n","  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n","  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n","  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n","FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = 'models/t5-small-direct-answer_first=False-random_facts=True.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"]}],"source":["!python3 evaluation.py --model='t5-small' --strategy='direct' --no-examplars --no-answer_first --random_facts --no-load_checkpoint  --size=-1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a4xmB7YYqhyF"},"outputs":[],"source":["!python3 evaluation.py --model='t5-small' --strategy='direct' --no-examplars --no-answer_first --no-random_facts --no-load_checkpoint  --size=-1"]},{"cell_type":"markdown","metadata":{"id":"3FJsAxi3OdTb"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQLmQsT4QpVT"},"outputs":[],"source":["from evaluation import load_responses, EvaluationConfig\n","from data_loaders import load_TestData\n","import json\n","config = EvaluationConfig(\"flan-t5-small-direct\", examplars=False, data_path=\"data/MultihopEvaluation/\", results_path=\"results/\", create_tokenizer=False)\n","responses = load_responses(config)\n","test_set = load_TestData(config.generate_test_set_file(), n_examples=5)\n","with open(config.generate_results_file(), \"r\") as f:\n","    results = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P4YSKMMUy23E"},"outputs":[],"source":["for idx in range(5):\n","    print(\"Example:\", idx)\n","    print(test_set[idx][\"prompt\"])\n","    display(\"Reference text:\", test_set[idx][\"target\"])\n","    print(\"True answer:\", test_set[idx][\"answer\"])\n","    print()\n","    print(\"--------\")\n","    print(\"T5 response\")\n","    display(\"Response:\", responses[idx][\"response\"])\n","    print(\"Answer:\", responses[idx][\"answer\"])\n","    print(\"--------\")\n","    print(\"\\n\\n\")\n","display(\"T5 Results\")\n","display(results[\"macro_results\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lTBhfV2r88eL"},"outputs":[],"source":["import pandas as pd\n","\n","pd.DataFrame(results[\"micro_results\"])"]},{"cell_type":"markdown","metadata":{"id":"MX5oxvFuMgd7"},"source":["# Macro Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H88ZwMgMMgd7"},"outputs":[],"source":["import os, json\n","import pandas as pd\n","\n","path_to_json = './results'\n","\n","json_files = [pos_json for pos_json in sorted(os.listdir(path_to_json)) if pos_json.endswith('.json')]\n","\n","jsons_data = pd.DataFrame(columns=['Model', 'Finetune', 'With Examplars', 'Accuracy', 'F1-1', 'F1-2', 'BLEU-1', 'BLEU-2', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L'])\n","\n","for index, js in enumerate(json_files):\n","    with open(os.path.join(path_to_json, js)) as json_file:\n","        json_text = json.load(json_file)\n","\n","        # Get rid of unnecessary filename and extension.\n","        js = js.replace(\"-results.json\", \"\")\n","\n","        # Mark \"With Examplars\" column\n","        if (\"-with-examplars\" in js):\n","            model = js.replace(\"-with-examplars\", \"\")\n","            examplars = 'Y'\n","        else:\n","            model = js.replace(\"-without-examplars\", \"\")\n","            examplars = 'N'\n","\n","        # Mark \"Finetune\" column\n","        if (\"-direct\" in model):\n","            model = model.replace(\"-direct\", \"\")\n","            fine_tune = \"Direct\"\n","        elif (\"-self-ask\" in model):\n","            model = model.replace(\"-self-ask\", \"\")\n","            fine_tune = \"Self Ask\"\n","        else:\n","            fine_tune = \"N/A\"\n","\n","        # Build data frame row\n","        accuracy = json_text['macro_results']['accuracy']\n","        f1_1 = json_text['macro_results']['F1-1']\n","        f1_2 = json_text['macro_results']['F1-2']\n","        bleu_1 = json_text['macro_results']['bleu-1']\n","        bleu_2 = json_text['macro_results']['bleu-2']\n","        rouge_1 = json_text['macro_results']['rouge-1']\n","        rouge_2 = json_text['macro_results']['rouge-2']\n","        rouge_L = json_text['macro_results']['rouge-L']\n","\n","        # Add row to data frame\n","        jsons_data.loc[index] = [model, fine_tune, examplars, accuracy, f1_1, f1_2, bleu_1, bleu_2, rouge_1, rouge_2, rouge_L]\n","\n","# print result\n","jsons_data\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xwbqkXOcMgd8"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}