{"cells":[{"cell_type":"markdown","metadata":{"id":"fA4ROD7HaSJL"},"source":["## Setup"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":297321,"status":"ok","timestamp":1709604983556,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":360},"id":"LK63fBfDbM5D","outputId":"2df462eb-6c48-40bb-e9d7-ff53d8b7d34f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow==2.12.1\n","  Downloading tensorflow-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (23.5.26)\n","Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.1)\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (1.62.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (3.9.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (0.4.23)\n","Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.1)\n","  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (16.0.6)\n","Collecting numpy<=1.24.3,>=1.22 (from tensorflow==2.12.1)\n","  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (1.16.0)\n","Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.1)\n","  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.1)\n","  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (2.4.0)\n","Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.12.1)\n","  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.1) (0.36.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.1) (0.42.0)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.1) (0.2.0)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.1) (1.11.4)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.1) (2.27.0)\n","Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.1)\n","  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.1) (3.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.1) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.1) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.1) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (2.1.5)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.1) (3.2.2)\n","Installing collected packages: typing-extensions, tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.10.0\n","    Uninstalling typing_extensions-4.10.0:\n","      Successfully uninstalled typing_extensions-4.10.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.15.0\n","    Uninstalling tensorflow-estimator-2.15.0:\n","      Successfully uninstalled tensorflow-estimator-2.15.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.4\n","    Uninstalling gast-0.5.4:\n","      Successfully uninstalled gast-0.5.4\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.2.0\n","    Uninstalling google-auth-oauthlib-1.2.0:\n","      Successfully uninstalled google-auth-oauthlib-1.2.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sqlalchemy 2.0.27 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n","pydantic 2.6.3 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n","pydantic-core 2.16.3 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.12.0 numpy-1.24.3 tensorboard-2.12.3 tensorflow-2.12.1 tensorflow-estimator-2.12.0 typing-extensions-4.5.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"81fc069304c543428348d6073abd65c1","pip_warning":{"packages":["numpy"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.2)\n","Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n","Requirement already satisfied: loguru in /usr/local/lib/python3.10/dist-packages (0.7.2)\n","Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.24.3)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.2)\n","Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.24.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.38.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.27.2)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.2)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"]}],"source":["# !pip install pytest\n","!pip install tensorflow==\"2.12.1\"\n","!pip install transformers\n","!pip install sentencepiece\n","!pip install tokenizers\n","!pip install nltk\n","!pip install loguru\n","!pip install rouge-score\n","!pip install peft"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":129,"status":"ok","timestamp":1709604509863,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":360},"id":"fO0ZlSt6vUQr","outputId":"20a10483-3155-4556-9633-5a65f25d1812"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Mar  5 02:08:29 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0              23W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"markdown","metadata":{"id":"mMShMWVHvT-r"},"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41633,"status":"ok","timestamp":1709604551494,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":360},"id":"1djF5RoWXDce","outputId":"b6e15ee0-dd95-4796-bc63-0cca841166e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":247,"status":"ok","timestamp":1709604551734,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":360},"id":"Hp1iPONkluJM","outputId":"5808bf9a-e459-4e66-895c-86327781a5a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/projects/compositional-reasoning-finetuning\n"]}],"source":["%cd drive/MyDrive/projects/compositional-reasoning-finetuning"]},{"cell_type":"markdown","metadata":{"id":"EHxz0wAdNimM"},"source":["# Run Evaluation"]},{"cell_type":"markdown","metadata":{"id":"sFhxO_zQSNrO"},"source":["self-ask, no examplars, no answer first, no random facts"]},{"cell_type":"markdown","metadata":{"id":"PtGH4E_dXJ70"},"source":["- [X] python3 evaluation.py --model='t5-small' --strategy='self_ask' --no-examplars --no-answer_first --no-random_facts --no-load_checkpoint  --size=-1 --batch_size=128\n","- [X] python3 evaluation.py --model='t5-small' --strategy='self_ask' --examplars --no-answer_first --no-random_facts --no-load_checkpoint  --size=-1 --batch_size=128\n","- [X] python3 evaluation.py --model='t5-small' --strategy='self_ask' --no-examplars --answer_first --no-random_facts --no-load_checkpoint  --size=-1 --batch_size=128\n","- [X] python3 evaluation.py --model='t5-small' --strategy='self_ask' --examplars --answer_first --no-random_facts --no-load_checkpoint  --size=-1 --batch_size=128\n","- [X] python3 evaluation.py --model='t5-small' --strategy='self_ask' --no-examplars --no-answer_first --random_facts --no-load_checkpoint  --size=-1 --batch_size=128\n","- [X] python3 evaluation.py --model='t5-small' --strategy='self_ask' --examplars --no-answer_first --random_facts --no-load_checkpoint  --size=-1 --batch_size=128\n","- [ ] python3 evaluation.py --model='t5-small' --strategy='direct' --no-examplars --no-answer_first --random_facts --no-load_checkpoint  --size=-1 --batch_size=128\n","- [X] python3 evaluation.py --model='t5-small' --strategy='direct' --no-examplars --no-answer_first --no-random_facts --no-load_checkpoint  --size=-1 --batch_size=128"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":508089,"status":"ok","timestamp":1709605500871,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":360},"id":"NkK2EtL9NhtG","outputId":"28fe7d54-7820-46ca-a57b-4492f7293165"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-03-05 02:16:33.668975: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-03-05 02:16:33.722283: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-03-05 02:16:33.722931: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-03-05 02:16:34.740696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_runtime.py:184: UserWarning: Pydantic is installed but cannot be imported. Please check your installation. `huggingface_hub` will default to not using Pydantic. Error message: '{e}'\n","  warnings.warn(\n","\u001b[32m2024-03-05 02:16:43.600\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m570\u001b[0m - \u001b[34m\u001b[1mExamplars parameter -> False\u001b[0m\n","\u001b[32m2024-03-05 02:16:43.601\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m571\u001b[0m - \u001b[34m\u001b[1mCheckpoint loader parameter -> False\u001b[0m\n","\u001b[32m2024-03-05 02:16:43.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_set_t5_tokenizer\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mLoading tokenizer t5-small with max length of 300\u001b[0m\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","\u001b[32m2024-03-05 02:16:43.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m577\u001b[0m - \u001b[1mTest set pointing to file: data/MultihopEvaluation/self_ask-answer_first=False-random_facts=False-without-examplars.json\u001b[0m\n","\u001b[32m2024-03-05 02:16:43.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m578\u001b[0m - \u001b[1mResponses will be saved to: results/t5-small-self_ask-answer_first=False-random_facts=False-without-examplars-responses.json\u001b[0m\n","\u001b[32m2024-03-05 02:16:43.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m579\u001b[0m - \u001b[1mResults will be saved to: results/t5-small-self_ask-answer_first=False-random_facts=False-without-examplars-results.json\u001b[0m\n","\u001b[32m2024-03-05 02:16:44.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mLoading t5-small model\u001b[0m\n","2024-03-05 02:16:44.189961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-05 02:16:44.511436: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n","\n","All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","\u001b[32m2024-03-05 02:16:53.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m192\u001b[0m - \u001b[1mLoading finetuned model weights from: models/t5-small-self_ask-answer_first=False-random_facts=False.h5\u001b[0m\n","\u001b[32m2024-03-05 02:16:58.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_progress\u001b[0m:\u001b[36m499\u001b[0m - \u001b[1mNo existing progress detected... starting from scratch.\u001b[0m\n","\u001b[32m2024-03-05 02:16:58.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m596\u001b[0m - \u001b[1mCollecting model responses...\u001b[0m\n","  0% 0/66 [00:00<?, ?it/s]2024-03-05 02:17:01.578896: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 148897792 exceeds 10% of free system memory.\n","2024-03-05 02:17:02.197750: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 148897792 exceeds 10% of free system memory.\n","2024-03-05 02:17:04.089006: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 148897792 exceeds 10% of free system memory.\n","2024-03-05 02:17:04.721725: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 148897792 exceeds 10% of free system memory.\n","2024-03-05 02:17:06.844452: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 148897792 exceeds 10% of free system memory.\n","2024-03-05 02:17:19.375055: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x5700e46fdd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2024-03-05 02:17:19.375102: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Host, Default Version\n","2024-03-05 02:17:19.379081: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2024-03-05 02:17:19.396646: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","  3% 2/66 [07:59<4:15:42, 239.73s/it]\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/projects/compositional-reasoning-finetuning/evaluation.py\", line 615, in <module>\n","    tokenized_responses = ask_questions(model, question_encodings, config)\n","  File \"/content/drive/MyDrive/projects/compositional-reasoning-finetuning/evaluation.py\", line 259, in ask_questions\n","    return lm.generate(questions.input_ids, max_length=200)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/tf_utils.py\", line 816, in generate\n","    model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/tf_utils.py\", line 1071, in _prepare_encoder_decoder_kwargs_for_generation\n","    encoder_outputs = encoder(**encoder_kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n","    outputs = call_fn(inputs, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 428, in run_call_with_unpacked_inputs\n","    return func(self, **unpacked_inputs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 855, in call\n","    layer_outputs = layer_module(\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n","    outputs = call_fn(inputs, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 683, in call\n","    hidden_states = self.layer[-1](hidden_states, training=training)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n","    outputs = call_fn(inputs, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 193, in call\n","    dense_output = self.DenseReluDense(normed_hidden_states, training=training)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n","    outputs = call_fn(inputs, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 117, in call\n","    hidden_states = self.wi(hidden_states)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n","    outputs = call_fn(inputs, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/layers/core/dense.py\", line 244, in call\n","    outputs = tf.tensordot(inputs, self.kernel, [[rank - 1], [0]])\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\", line 1176, in op_dispatch_handler\n","    return dispatch_target(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_ops.py\", line 5160, in tensordot\n","    ab_matmul = matmul(a_reshape, b_reshape)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\", line 1176, in op_dispatch_handler\n","    return dispatch_target(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_ops.py\", line 3766, in matmul\n","    return gen_math_ops.mat_mul(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 6013, in mat_mul\n","    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n","KeyboardInterrupt\n"]}],"source":["!python3 evaluation.py --model='t5-small' --strategy='self_ask' --no-examplars --no-answer_first --no-random_facts --no-load_checkpoint  --size=-1 --batch_size=128"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10760,"status":"ok","timestamp":1709318085085,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":360},"id":"pcNmrUYBxZgb","outputId":"1f480090-0f52-4b46-9fc5-0843a9ef66ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-03-01 18:34:35.106983: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-01 18:34:35.107031: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-01 18:34:35.108372: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-01 18:34:35.115570: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-03-01 18:34:36.159559: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[32m2024-03-01 18:34:41.809\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m570\u001b[0m - \u001b[34m\u001b[1mExamplars parameter -> True\u001b[0m\n","\u001b[32m2024-03-01 18:34:41.810\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m571\u001b[0m - \u001b[34m\u001b[1mCheckpoint loader parameter -> False\u001b[0m\n","\u001b[32m2024-03-01 18:34:41.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_set_t5_tokenizer\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mLoading tokenizer t5-small with max length of 300\u001b[0m\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","\u001b[32m2024-03-01 18:34:42.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m577\u001b[0m - \u001b[1mTest set pointing to file: data/MultihopEvaluation/self_ask-answer_first=False-random_facts=False-with-examplars.json\u001b[0m\n","\u001b[32m2024-03-01 18:34:42.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m578\u001b[0m - \u001b[1mResponses will be saved to: results/t5-small-self_ask-answer_first=False-random_facts=False-with-examplars-responses.json\u001b[0m\n","\u001b[32m2024-03-01 18:34:42.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m579\u001b[0m - \u001b[1mResults will be saved to: results/t5-small-self_ask-answer_first=False-random_facts=False-with-examplars-results.json\u001b[0m\n","\u001b[32m2024-03-01 18:34:42.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m591\u001b[0m - \u001b[1mLoading t5-small model\u001b[0m\n","2024-03-01 18:34:42.575273: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.582883: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.583139: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.583822: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.584082: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.584278: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.767624: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.767915: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.768055: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2024-03-01 18:34:42.768136: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-03-01 18:34:42.768281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n","\n","All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/projects/compositional-reasoning-finetuning/evaluation.py\", line 592, in <module>\n","    model = load_model(config)\n","  File \"/content/drive/MyDrive/projects/compositional-reasoning-finetuning/evaluation.py\", line 190, in load_model\n","    keras_model = build_t5_training_wrapper_model(t5_model, max_length=max_length)\n","  File \"/content/drive/MyDrive/projects/compositional-reasoning-finetuning/training_utils.py\", line 147, in build_t5_training_wrapper_model\n","    t5_logits = t5_model(input_ids, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids)[0]\n","  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\", line 70, in error_handler\n","    raise e.with_traceback(filtered_tb) from None\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 428, in run_call_with_unpacked_inputs\n","    return func(self, **unpacked_inputs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 1446, in call\n","    encoder_outputs = self.encoder(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 428, in run_call_with_unpacked_inputs\n","    return func(self, **unpacked_inputs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 767, in call\n","    check_embeddings_within_bounds(input_ids, self.embed_tokens.input_dim)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/tf_utils.py\", line 163, in check_embeddings_within_bounds\n","    tf.debugging.assert_less(\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/tf_op_layer.py\", line 119, in handle\n","    return TFOpLambda(op)(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n","    raise e.with_traceback(filtered_tb) from None\n","TypeError: Exception encountered when calling layer 'encoder' (type TFT5MainLayer).\n","\n","Could not build a TypeSpec for name: \"tf.debugging.assert_less/assert_less/Assert/Assert\"\n","op: \"Assert\"\n","input: \"tf.debugging.assert_less/assert_less/All\"\n","input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_0\"\n","input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_1\"\n","input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_2\"\n","input: \"Placeholder\"\n","input: \"tf.debugging.assert_less/assert_less/Assert/Assert/data_4\"\n","input: \"tf.debugging.assert_less/assert_less/y\"\n","attr {\n","  key: \"T\"\n","  value {\n","    list {\n","      type: DT_STRING\n","      type: DT_STRING\n","      type: DT_STRING\n","      type: DT_INT32\n","      type: DT_STRING\n","      type: DT_INT32\n","    }\n","  }\n","}\n","attr {\n","  key: \"summarize\"\n","  value {\n","    i: 3\n","  }\n","}\n"," of unsupported type <class 'tensorflow.python.framework.ops.Operation'>.\n","\n","Call arguments received by layer 'encoder' (type TFT5MainLayer):\n","  • input_ids=<KerasTensor: shape=(None, 300) dtype=int32 (created by layer 'input_ids')>\n","  • attention_mask=<KerasTensor: shape=(None, 300) dtype=int32 (created by layer 'attention_mask')>\n","  • encoder_hidden_states=None\n","  • encoder_attention_mask=None\n","  • inputs_embeds=None\n","  • head_mask=None\n","  • encoder_head_mask=None\n","  • past_key_values=None\n","  • use_cache=None\n","  • output_attentions=False\n","  • output_hidden_states=False\n","  • return_dict=True\n","  • training=False\n"]}],"source":["!python3 evaluation.py --model='t5-small' --strategy='self_ask' --examplars --no-answer_first --no-random_facts --no-load_checkpoint  --size=-1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CchiGgv1_TsV"},"outputs":[],"source":["!python3 evaluation.py --model='t5-small' --strategy='self_ask' --examplars --answer_first --no-random_facts --no-load_checkpoint  --size=-1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X5XUo2gVO2MQ"},"outputs":[],"source":["!python3 evaluation.py --model='t5-small' --strategy='self_ask' --no-examplars --answer_first --no-random_facts --no-load_checkpoint  --size=-1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YMyB_pFskH1z"},"outputs":[],"source":["!python3 evaluation.py --model='t5-small' --strategy='self_ask' --examplars --no-answer_first --random_facts --no-load_checkpoint  --size=-1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qyRfPM80xCSi"},"outputs":[],"source":["!python3 evaluation.py --model='t5-small' --strategy='self_ask' --no-examplars --no-answer_first --random_facts --no-load_checkpoint  --size=-1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36160,"status":"ok","timestamp":1706470797867,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":360},"id":"mwXbuB2AqdXC","outputId":"887aef0f-b14d-4001-9153-79e9266dea99"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-01-28 19:39:23.698816: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-01-28 19:39:23.698873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-01-28 19:39:23.700341: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-01-28 19:39:23.708366: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-01-28 19:39:26.324263: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[32m2024-01-28 19:39:38.570\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m543\u001b[0m - \u001b[34m\u001b[1mExamplars parameter -> False\u001b[0m\n","\u001b[32m2024-01-28 19:39:38.572\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m544\u001b[0m - \u001b[34m\u001b[1mCheckpoint loader parameter -> False\u001b[0m\n","\u001b[32m2024-01-28 19:39:38.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_set_t5_tokenizer\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mLoading tokenizer t5-small with max length of 300\u001b[0m\n","tokenizer_config.json: 100% 2.32k/2.32k [00:00<00:00, 9.17MB/s]\n","spiece.model: 100% 792k/792k [00:00<00:00, 10.6MB/s]\n","tokenizer.json: 100% 1.39M/1.39M [00:00<00:00, 11.9MB/s]\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","\u001b[32m2024-01-28 19:39:39.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m550\u001b[0m - \u001b[1mTest set pointing to file: data/MultihopEvaluation/direct-answer_first=False-random_facts=True-without-examplars.json\u001b[0m\n","\u001b[32m2024-01-28 19:39:39.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m551\u001b[0m - \u001b[1mResponses will be saved to: results/t5-small-direct-answer_first=False-random_facts=True-without-examplars-responses.json\u001b[0m\n","\u001b[32m2024-01-28 19:39:39.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m552\u001b[0m - \u001b[1mResults will be saved to: results/t5-small-direct-answer_first=False-random_facts=True-without-examplars-results.json\u001b[0m\n","\u001b[32m2024-01-28 19:39:40.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m564\u001b[0m - \u001b[1mLoading t5-small model\u001b[0m\n","config.json: 100% 1.21k/1.21k [00:00<00:00, 5.81MB/s]\n","model.safetensors: 100% 242M/242M [00:01<00:00, 186MB/s]\n","2024-01-28 19:39:42.223993: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.518467: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.518880: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.519710: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.520019: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.520272: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.781261: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.781603: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.781823: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2024-01-28 19:39:42.781918: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-01-28 19:39:42.782144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n","\n","All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","\u001b[32m2024-01-28 19:39:54.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m179\u001b[0m - \u001b[1mLoading finetuned model weights from: models/t5-small-direct-answer_first=False-random_facts=True.h5\u001b[0m\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/projects/compositional-reasoning-finetuning/evaluation.py\", line 565, in <module>\n","    model = load_model(config)\n","  File \"/content/drive/MyDrive/projects/compositional-reasoning-finetuning/evaluation.py\", line 180, in load_model\n","    keras_model.load_weights(path)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n","    raise e.with_traceback(filtered_tb) from None\n","  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\", line 567, in __init__\n","    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n","  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\", line 231, in make_fid\n","    fid = h5f.open(name, flags, fapl=fapl)\n","  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n","  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n","  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n","FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = 'models/t5-small-direct-answer_first=False-random_facts=True.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"]}],"source":["!python3 evaluation.py --model='t5-small' --strategy='direct' --no-examplars --no-answer_first --random_facts --no-load_checkpoint  --size=-1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a4xmB7YYqhyF"},"outputs":[],"source":["!python3 evaluation.py --model='t5-small' --strategy='direct' --no-examplars --no-answer_first --no-random_facts --no-load_checkpoint  --size=-1"]},{"cell_type":"markdown","metadata":{"id":"3FJsAxi3OdTb"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQLmQsT4QpVT"},"outputs":[],"source":["from evaluation import load_responses, EvaluationConfig\n","from data_loaders import load_TestData\n","import json\n","config = EvaluationConfig(\"flan-t5-small-direct\", examplars=False, data_path=\"data/MultihopEvaluation/\", results_path=\"results/\", create_tokenizer=False)\n","responses = load_responses(config)\n","test_set = load_TestData(config.generate_test_set_file(), n_examples=5)\n","with open(config.generate_results_file(), \"r\") as f:\n","    results = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P4YSKMMUy23E"},"outputs":[],"source":["for idx in range(5):\n","    print(\"Example:\", idx)\n","    print(test_set[idx][\"prompt\"])\n","    display(\"Reference text:\", test_set[idx][\"target\"])\n","    print(\"True answer:\", test_set[idx][\"answer\"])\n","    print()\n","    print(\"--------\")\n","    print(\"T5 response\")\n","    display(\"Response:\", responses[idx][\"response\"])\n","    print(\"Answer:\", responses[idx][\"answer\"])\n","    print(\"--------\")\n","    print(\"\\n\\n\")\n","display(\"T5 Results\")\n","display(results[\"macro_results\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lTBhfV2r88eL"},"outputs":[],"source":["import pandas as pd\n","\n","pd.DataFrame(results[\"micro_results\"])"]},{"cell_type":"markdown","metadata":{"id":"MX5oxvFuMgd7"},"source":["# Macro Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H88ZwMgMMgd7"},"outputs":[],"source":["import os, json\n","import pandas as pd\n","\n","path_to_json = './results'\n","\n","json_files = [pos_json for pos_json in sorted(os.listdir(path_to_json)) if pos_json.endswith('.json')]\n","\n","jsons_data = pd.DataFrame(columns=['Model', 'Finetune', 'With Examplars', 'Accuracy', 'F1-1', 'F1-2', 'BLEU-1', 'BLEU-2', 'ROUGE-1', 'ROUGE-2', 'ROUGE-L'])\n","\n","for index, js in enumerate(json_files):\n","    with open(os.path.join(path_to_json, js)) as json_file:\n","        json_text = json.load(json_file)\n","\n","        # Get rid of unnecessary filename and extension.\n","        js = js.replace(\"-results.json\", \"\")\n","\n","        # Mark \"With Examplars\" column\n","        if (\"-with-examplars\" in js):\n","            model = js.replace(\"-with-examplars\", \"\")\n","            examplars = 'Y'\n","        else:\n","            model = js.replace(\"-without-examplars\", \"\")\n","            examplars = 'N'\n","\n","        # Mark \"Finetune\" column\n","        if (\"-direct\" in model):\n","            model = model.replace(\"-direct\", \"\")\n","            fine_tune = \"Direct\"\n","        elif (\"-self-ask\" in model):\n","            model = model.replace(\"-self-ask\", \"\")\n","            fine_tune = \"Self Ask\"\n","        else:\n","            fine_tune = \"N/A\"\n","\n","        # Build data frame row\n","        accuracy = json_text['macro_results']['accuracy']\n","        f1_1 = json_text['macro_results']['F1-1']\n","        f1_2 = json_text['macro_results']['F1-2']\n","        bleu_1 = json_text['macro_results']['bleu-1']\n","        bleu_2 = json_text['macro_results']['bleu-2']\n","        rouge_1 = json_text['macro_results']['rouge-1']\n","        rouge_2 = json_text['macro_results']['rouge-2']\n","        rouge_L = json_text['macro_results']['rouge-L']\n","\n","        # Add row to data frame\n","        jsons_data.loc[index] = [model, fine_tune, examplars, accuracy, f1_1, f1_2, bleu_1, bleu_2, rouge_1, rouge_2, rouge_L]\n","\n","# print result\n","jsons_data\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xwbqkXOcMgd8"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
