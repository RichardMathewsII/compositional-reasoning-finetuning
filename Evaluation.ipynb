{"cells":[{"cell_type":"markdown","metadata":{"id":"fA4ROD7HaSJL"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51356,"status":"ok","timestamp":1689195424785,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":300},"id":"LK63fBfDbM5D","outputId":"55d9e7c2-73bd-4b42-937f-ea3c0e17c731"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (7.2.2)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest) (23.1.0)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest) (23.1)\n","Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.2.0)\n","Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.1.2)\n","Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.1)\n","Collecting transformers\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.13.3)\n","Collecting thefuzz\n","  Downloading thefuzz-0.19.0-py2.py3-none-any.whl (17 kB)\n","Installing collected packages: thefuzz\n","Successfully installed thefuzz-0.19.0\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n","Collecting loguru\n","  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: loguru\n","Successfully installed loguru-0.7.0\n"]}],"source":["!pip install pytest\n","!pip install transformers\n","!pip install sentencepiece\n","!pip install tokenizers\n","!pip install thefuzz\n","!pip install nltk\n","!pip install loguru"]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fO0ZlSt6vUQr","executionInfo":{"status":"ok","timestamp":1689192845701,"user_tz":300,"elapsed":378,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"}},"outputId":"7eba86c6-596b-4e23-c38a-c134ceec083a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Jul 12 20:14:05 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"mMShMWVHvT-r"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19539,"status":"ok","timestamp":1689263349267,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":300},"id":"1djF5RoWXDce","outputId":"3fe06d86-360e-40d0-f8dd-e809ae23a36b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":146,"status":"ok","timestamp":1689197749632,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":300},"id":"Hp1iPONkluJM","outputId":"55fa1050-d757-425a-f344-481d06e24521"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/projects/compositional-reasoning-finetuning\n"]}],"source":["%cd drive/MyDrive/projects/compositional-reasoning-finetuning"]},{"cell_type":"markdown","metadata":{"id":"tSoay8mHaP8h"},"source":["## Git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21070,"status":"ok","timestamp":1689180547498,"user":{"displayName":"Richard Mathews","userId":"02196021105251478486"},"user_tz":300},"id":"jgbWQHb1NnLW","outputId":"4b172e1f-b305-4509-bd73-10dcda0d9ac8"},"outputs":[{"output_type":"stream","name":"stdout","text":["remote: Enumerating objects: 15, done.\u001b[K\n","remote: Counting objects:   7% (1/14)\u001b[K\rremote: Counting objects:  14% (2/14)\u001b[K\rremote: Counting objects:  21% (3/14)\u001b[K\rremote: Counting objects:  28% (4/14)\u001b[K\rremote: Counting objects:  35% (5/14)\u001b[K\rremote: Counting objects:  42% (6/14)\u001b[K\rremote: Counting objects:  50% (7/14)\u001b[K\rremote: Counting objects:  57% (8/14)\u001b[K\rremote: Counting objects:  64% (9/14)\u001b[K\rremote: Counting objects:  71% (10/14)\u001b[K\rremote: Counting objects:  78% (11/14)\u001b[K\rremote: Counting objects:  85% (12/14)\u001b[K\rremote: Counting objects:  92% (13/14)\u001b[K\rremote: Counting objects: 100% (14/14)\u001b[K\rremote: Counting objects: 100% (14/14), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 9 (delta 4), reused 7 (delta 3), pack-reused 0\u001b[K\n","Unpacking objects: 100% (9/9), 201.32 KiB | 242.00 KiB/s, done.\n","From https://github.com/RichardMathewsII/compositional-reasoning-finetuning\n","   913f1b7..3e93a54  main        -> origin/main\n","   6e23794..75775c4  alpaca-lora -> origin/alpaca-lora\n","   a8178de..47a0f36  sk          -> origin/sk\n","Updating b7e0a75..3e93a54\n","Fast-forward\n"," training_demo.ipynb | 223 \u001b[32m+++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m---\u001b[m\n"," training_utils.py   |  91 \u001b[32m++++++++++++++++++++\u001b[m\u001b[31m-\u001b[m\n"," 2 files changed, 304 insertions(+), 10 deletions(-)\n"]}],"source":["!git pull"]},{"cell_type":"markdown","metadata":{"id":"dfKlPhSyooAA"},"source":["Git Push"]},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vWpAXMKOB8NG","executionInfo":{"status":"ok","timestamp":1689197753329,"user_tz":300,"elapsed":325,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"}},"outputId":"f2282a96-4d8e-4114-b74a-e4fba0f8e193"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git restore <file>...\" to discard changes in working directory)\n","\t\u001b[31mmodified:   analyze_splits.ipynb\u001b[m\n","\t\u001b[31mmodified:   data_adaptor.py\u001b[m\n","\t\u001b[31mmodified:   data_generation.py\u001b[m\n","\t\u001b[31mmodified:   evaluation.py\u001b[m\n","\t\u001b[31mmodified:   logs/data_generation.log\u001b[m\n","\t\u001b[31mmodified:   token_stats.py\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\t\u001b[31mlogs/evaluation.log\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":872,"status":"ok","timestamp":1689197894635,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":300},"id":"6of4bOwQ2P2J","outputId":"d81bc229-eda4-49dd-8b95-112b495c9fe2"},"outputs":[{"output_type":"stream","name":"stdout","text":["[main d2b95bf] updates\n"," 7 files changed, 27 insertions(+), 906 deletions(-)\n"," rewrite analyze_splits.ipynb (98%)\n"," rewrite logs/data_generation.log (85%)\n"," create mode 100644 logs/evaluation.log\n"]}],"source":["!git config --global user.email \"richardmathews.ai@gmail.com\"\n","!git config --global user.name \"RichardMathewsII\"\n","!git add .\n","!git commit -m \"updates\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4094,"status":"ok","timestamp":1689197909933,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":300},"id":"sz-ikc9Ckqwy","outputId":"bfcf8a42-a720-4b80-aa7b-30ecd4a934f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter token: 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\n"]}],"source":["import os\n","from getpass import getpass\n","import urllib\n","\n","pat = input('Enter token: ')\n","\n","cmd_string = 'git push https://RichardMathewsII:{0}@github.com/RichardMathewsII/compositional-reasoning-finetuning.git'.format(pat)\n","\n","os.system(cmd_string)\n","cmd_string, pat = \"\", \"\" # removing the password from the variable"]},{"cell_type":"markdown","metadata":{"id":"FRcvQWa_bK9_"},"source":["## Pytest"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIbnDDl8Wfup","outputId":"d4f4d328-8c15-4f47-c62d-cbf597566e98"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m============================= test session starts ==============================\u001b[0m\n","platform linux -- Python 3.10.12, pytest-7.2.2, pluggy-1.2.0 -- /usr/bin/python3\n","cachedir: .pytest_cache\n","rootdir: /content/drive/MyDrive/W266 Project/compositional-reasoning-finetuning\n","plugins: anyio-3.7.1\n","\u001b[1mcollecting ... \u001b[0m"]}],"source":["!pytest . -v"]},{"cell_type":"markdown","metadata":{"id":"3FJsAxi3OdTb"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7nPH93xbOfeB","outputId":"3469eb7b-df87-4a51-ba6a-fdb0b88e1314"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-07-12 19:55:56.499831: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-07-12 19:55:57.591497: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/usr/local/lib/python3.10/dist-packages/thefuzz/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n","  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"]}],"source":["!python evaluation.py --model \"t5-small\" --dataset \"direct\" --size 5 --batch_size 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQLmQsT4QpVT"},"outputs":[],"source":["from evaluation import load_responses, EvaluationConfig\n","from data_loaders import load_TestData\n","from tqdm import tqdm\n","import json\n","config = EvaluationConfig(\"t5-small\", \"direct\", \"data/MultihopEvaluation/\", create_tokenizer=False)\n","responses = load_responses(config)\n","test_set = load_TestData(strategy=config.dataset, n_examples=5)\n","with open(\"data/MultihopEvaluation/t5-small-direct-results.json\", \"r\") as f:\n","    results = json.load(f)"]},{"cell_type":"code","source":["for idx in range(5):\n","    print(test_set[idx][\"prompt\"])\n","    print(test_set[idx][\"target\"])\n","    print(test_set[idx][\"answer\"])\n","    print(\"--------\")\n","    print(\"T5 response\")\n","    print(responses[idx][\"response\"])\n","    print(responses[idx][\"answer\"])\n","    print(\"--------\")\n","    print(\"Metrics\")\n","    micro_results = results[\"micro_results\"]\n","    print(\"correct: \", micro_results[\"correct\"][idx])\n","    print(\"precision: \", micro_results[\"precision\"][idx])\n","    print(\"recall: \", micro_results[\"recall\"][idx])\n","    print(\"F1 score: \", micro_results[\"F1\"][idx])\n","    print(\"--------\")\n","    print()\n","    print()\n","print(\"T5 Results\")\n","print(results[\"macro_results\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P4YSKMMUy23E","executionInfo":{"status":"ok","timestamp":1689194013900,"user_tz":300,"elapsed":125,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"}},"outputId":"9a1b3c58-3224-492f-a1fa-eba20b16484c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fact #0: (Wojna polsko-ruska) is a 2009 Polish film directed by Xawery Żuławski based on the novel Polish-Russian War under the white-red flag by Dorota Masłowska.\n","Fact #1: He is the son of actress Małgorzata Braunek and director Andrzej Żuławski.\n","\n","Question: Who is the mother of the director of film Polish-Russian War (Film)?\n","Answer:\n","Małgorzata Braunek\n","Małgorzata Braunek\n","--------\n","T5 response\n","Während a sex interview with a sexy woman, he\n","Während a sex interview with a sexy woman, he\n","--------\n","Metrics\n","correct:  False\n","precision:  0.0\n","recall:  0.0\n","F1 score:  0\n","--------\n","\n","\n","Fact #0: Blind Shaft is a 2003 film about a pair of brutal con artists operating in the illegal coal mines of present- day northern China.\n","Fact #1: The Mask of Fu Manchu is a 1932 pre-Code adventure film directed by Charles Brabin.\n","\n","Question: Which film came out first, Blind Shaft or The Mask Of Fu Manchu?\n","Answer:\n","The Mask Of Fu Manchu\n","The Mask Of Fu Manchu\n","--------\n","T5 response\n",": The Mask of Fu Manchu is a 1932 pre-Code adventure film directed\n","The Mask of Fu Manchu is a 1932 pre-Code adventure film directed\n","--------\n","Metrics\n","correct:  True\n","precision:  0.3076923076923077\n","recall:  0.8\n","F1 score:  0.4444444444444444\n","--------\n","\n","\n","Fact #0: John was the second (but eldest surviving) son of Ernest I, Prince of Anhalt-Dessau, by his wife Margarete, daughter of Henry I, Duke of Münsterberg-Oels, and granddaughter of George of Poděbrady, King of Bohemia.\n","Fact #1: Ernest I, Prince of Anhalt-Dessau (died Dessau, 12 June 1516), was a German prince of the House of Ascania and ruler of the principality of Anhalt-Dessau.\n","\n","Question: When did John V, Prince Of Anhalt-Zerbst's father die?\n","Answer:\n","12 June 1516\n","12 June 1516\n","--------\n","T5 response\n","Während dessau, 12 June 1516, was the second (but eldest\n","Während dessau, 12 June 1516, was the second (but eldest\n","--------\n","Metrics\n","correct:  True\n","precision:  0.2\n","recall:  0.6666666666666666\n","F1 score:  0.30769230769230765\n","--------\n","\n","\n","Fact #0: Wearing Velvet Slippers under a Golden Umbrella (Pronounced as Katipa phanat see shwe htee hsaung) is a 1970 Burmese film directed by Maung Wunna starring Myat Mon, Myat Lay and Thet Naung.\n","Fact #1: Maung Wunna  was a two-time Myanmar Motion Picture Academy Awards-winning Burmese director and writer.\n","\n","Question: What is the award that the director of film Wearing Velvet Slippers Under A Golden Umbrella won?\n","Answer:\n","Myanmar Motion Picture Academy Awards\n","Myanmar Motion Picture Academy Awards\n","--------\n","T5 response\n",": What is the award that the director of film Wearing Velvet Slippers Under\n","What is the award that the director of film Wearing Velvet Slippers Under\n","--------\n","Metrics\n","correct:  False\n","precision:  0.0\n","recall:  0.0\n","F1 score:  0\n","--------\n","\n","\n","Fact #0: Ronnie Rocket is an unfinished film project written by David Lynch, who also intended to direct it.\n","Fact #1: Born to a middle-class family in Missoula, Montana, Lynch spent his childhood traveling around the United States before he studied painting at the Pennsylvania Academy of Fine Arts in Philadelphia, where he first made the transition to producing short films.\n","\n","Question: Where was the director of film Ronnie Rocket born?\n","Answer:\n","Missoula, Montana\n","Missoula, Montana\n","--------\n","T5 response\n","::0: Ronnie Rocket is an unfinished film project written by David\n","Ronnie Rocket is an unfinished film project written by David\n","--------\n","Metrics\n","correct:  False\n","precision:  0.0\n","recall:  0.0\n","F1 score:  0\n","--------\n","\n","\n","T5 Results\n","{'accuracy': 0.4, 'F1': 0.1504, 'precision': 0.1015, 'recall': 0.2933}\n"]}]},{"cell_type":"markdown","metadata":{"id":"7jXGLseLbWe7"},"source":["## T5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140,"referenced_widgets":["bf74035f74934a2c9b73a253d9d1eacf","032721addb4a4299aee5e7428a77c099","06f258ad34ec4f189920af82ca644b44","9f5a42f1226a4d438ee02af877c40b89","2acf12d8d9eb4fb7a7fb5721cebb8359","d91c871f11fc403391f83cea99fdd62c","9421ae4ece4244cc80cc9b1fc1a77d2d","35717a5b16a54ea69b12144c94d45a92","87bce51930f44a8db5f87c098fc4673a","ae8e39ac46bf461da28b52c9e68f321f","a757f5bf30a64b49b3e4c8528346f3a5"]},"executionInfo":{"elapsed":26260,"status":"ok","timestamp":1688768353959,"user":{"displayName":"Richard Mathews","userId":"02196021105251478486"},"user_tz":300},"id":"X99QuQE4UMCY","outputId":"9b34eec4-aaa3-42b9-d6ae-6a033673b406"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf74035f74934a2c9b73a253d9d1eacf","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n","\n","All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"]}],"source":["from transformers import TFT5ForConditionalGeneration\n","\n","model = TFT5ForConditionalGeneration.from_pretrained(\"t5-base\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ROircHWpkQt"},"outputs":[],"source":["from evaluation import EvaluationConfig, tokenize, ask_questions, decode\n","from data_loaders import load_TestData"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8729,"status":"ok","timestamp":1688768502336,"user":{"displayName":"Richard Mathews","userId":"02196021105251478486"},"user_tz":300},"id":"STOwm9Fk1GOd","outputId":"c6da40af-9c03-4ef9-ff3a-5c1c3d66485c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/tf_utils.py:854: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Fact #0: Éric Deflandre( born 2 August 1973 in Rocourt) is a former Belgian football right fullback.\n","Fact #1: Polly Swann( born 5 June 1988) is a British rower and a member of the Great Britain Rowing Team.\n","\n","Question: Who was born earlier, Polly Swann or Éric Deflandre?\n","Answer:\n","['Éric Deflandre( born 2 August 1973 in Rocourt) is']\n","correct answer: Éric Deflandre\n"]}],"source":["config = EvaluationConfig(\"t5-base\", \"toy_direct\", \"data/MultihopEvaluation/\", create_tokenizer=True)\n","test_set = load_TestData(config.dataset)\n","prefix = \"\"\n","text = prefix + test_set[0][\"prompt\"]\n","# make sure set_tokenizer has been executed\n","tokens = tokenize(text, config)\n","output = ask_questions(model, tokens, config)\n","result = decode(output, config)\n","print(text)\n","print(result)\n","\n","print(\"correct answer:\", test_set[0][\"target\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gB7QwjOBeyOK"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"032721addb4a4299aee5e7428a77c099":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d91c871f11fc403391f83cea99fdd62c","placeholder":"​","style":"IPY_MODEL_9421ae4ece4244cc80cc9b1fc1a77d2d","value":"Downloading model.safetensors: 100%"}},"06f258ad34ec4f189920af82ca644b44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_35717a5b16a54ea69b12144c94d45a92","max":891646390,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87bce51930f44a8db5f87c098fc4673a","value":891646390}},"2acf12d8d9eb4fb7a7fb5721cebb8359":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35717a5b16a54ea69b12144c94d45a92":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87bce51930f44a8db5f87c098fc4673a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9421ae4ece4244cc80cc9b1fc1a77d2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f5a42f1226a4d438ee02af877c40b89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae8e39ac46bf461da28b52c9e68f321f","placeholder":"​","style":"IPY_MODEL_a757f5bf30a64b49b3e4c8528346f3a5","value":" 892M/892M [00:10&lt;00:00, 62.1MB/s]"}},"a757f5bf30a64b49b3e4c8528346f3a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae8e39ac46bf461da28b52c9e68f321f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf74035f74934a2c9b73a253d9d1eacf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_032721addb4a4299aee5e7428a77c099","IPY_MODEL_06f258ad34ec4f189920af82ca644b44","IPY_MODEL_9f5a42f1226a4d438ee02af877c40b89"],"layout":"IPY_MODEL_2acf12d8d9eb4fb7a7fb5721cebb8359"}},"d91c871f11fc403391f83cea99fdd62c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}