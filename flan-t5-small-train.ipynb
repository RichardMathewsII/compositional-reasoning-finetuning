{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12084,
     "status": "ok",
     "timestamp": 1689957097114,
     "user": {
      "displayName": "Richard Mathews",
      "userId": "15085444626849988348"
     },
     "user_tz": 300
    },
    "id": "Iibm4YK8LLUG",
    "outputId": "4dd4b515-e03f-4a29-a42e-3a072ef08364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4440,
     "status": "ok",
     "timestamp": 1689957101549,
     "user": {
      "displayName": "Richard Mathews",
      "userId": "15085444626849988348"
     },
     "user_tz": 300
    },
    "id": "DZbmce7ULLUH",
    "outputId": "94b264a7-c09c-4fa6-8919-497513e17973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.99\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19447,
     "status": "ok",
     "timestamp": 1689957120992,
     "user": {
      "displayName": "Richard Mathews",
      "userId": "15085444626849988348"
     },
     "user_tz": 300
    },
    "id": "_R2UeFOnLLUH",
    "outputId": "74563c28-043f-48c0-8842-a3011d94f437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# This cell will authenticate you and mount your Drive in the Colab.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1689961754780,
     "user": {
      "displayName": "Richard Mathews",
      "userId": "15085444626849988348"
     },
     "user_tz": 300
    },
    "id": "wh_iGojfZ5b2",
    "outputId": "ff29c69d-7b9b-4348-eed6-3e9600495173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/projects/compositional-reasoning-finetuning\n"
     ]
    }
   ],
   "source": [
    "%cd drive/MyDrive/projects/compositional-reasoning-finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdvQ-88ifhJS"
   },
   "source": [
    "## Self-Ask Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4895,
     "status": "ok",
     "timestamp": 1689961759673,
     "user": {
      "displayName": "Richard Mathews",
      "userId": "15085444626849988348"
     },
     "user_tz": 300
    },
    "id": "h3niD4rSbFtO"
   },
   "outputs": [],
   "source": [
    "from training_utils import finetune_self_ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3544689,
     "status": "ok",
     "timestamp": 1689961233158,
     "user": {
      "displayName": "Richard Mathews",
      "userId": "15085444626849988348"
     },
     "user_tz": 300
    },
    "id": "XbAxM0SjfhJS",
    "outputId": "87ab873e-a051-4895-d09b-0da43b0922ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at google/flan-t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3188/3188 [==============================] - 3529s 1s/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.0052 - val_accuracy: 0.9989\n"
     ]
    }
   ],
   "source": [
    "# model_name\n",
    "model_name = 'google/flan-t5-small'\n",
    "\n",
    "# traing and validation file path\n",
    "train_file = 'data/FinetuningData/self_ask_train.json'\n",
    "valid_file = 'data/FinetuningData/self_ask_dev.json'\n",
    "\n",
    "# path and file name for checkpoint\n",
    "checkpoint_dir = 'checkpoints/flan-t5-small-self-ask/'\n",
    "checkpoint_filepath = checkpoint_dir + 'weights.{epoch:02d}-{batch:00005d}.hdf5'\n",
    "\n",
    "prev_checkpoint = \"checkpoints/flan-t5-small-self-ask/weights.02-00624.hdf5\" # resume from start of epoch 2\n",
    "\n",
    "# hyper parameters\n",
    "max_length = 300\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "\n",
    "model_wrapper = finetune_self_ask(\n",
    "    model_name,\n",
    "    train_file,\n",
    "    valid_file,\n",
    "    checkpoint_filepath,\n",
    "    max_length,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    previous_checkpoint=prev_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 8475,
     "status": "ok",
     "timestamp": 1689961459220,
     "user": {
      "displayName": "Richard Mathews",
      "userId": "15085444626849988348"
     },
     "user_tz": 300
    },
    "id": "xlr3uN0AYYBS"
   },
   "outputs": [],
   "source": [
    "model_wrapper.save(\"models/flan-t5-small-self-ask.h5\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "775gtb3gAsZY"
   },
   "source": [
    "## Direct Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1902483,
     "status": "ok",
     "timestamp": 1689963753626,
     "user": {
      "displayName": "Richard Mathews",
      "userId": "15085444626849988348"
     },
     "user_tz": 300
    },
    "id": "r0IICKIqAt4d",
    "outputId": "a7e3d20c-5033-49fb-f565-409001e521f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at google/flan-t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3296/3296 [==============================] - 1895s 560ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0022 - val_accuracy: 0.9995\n"
     ]
    }
   ],
   "source": [
    "# model_name\n",
    "model_name = 'google/flan-t5-small'\n",
    "\n",
    "# traing and validation file path\n",
    "train_file = 'data/FinetuningData/direct_train.json'\n",
    "valid_file = 'data/FinetuningData/direct_dev.json'\n",
    "\n",
    "# path and file name for checkpoint\n",
    "checkpoint_dir = 'checkpoints/flan-t5-small-direct/'\n",
    "checkpoint_filepath = checkpoint_dir + 'weights.resume.{epoch:02d}-{batch:00005d}.hdf5'\n",
    "\n",
    "prev_checkpoint = \"checkpoints/flan-t5-small-direct/weights.02-00704.hdf5\" # resume from start of epoch 2\n",
    "\n",
    "# hyper parameters\n",
    "max_length = 130\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "\n",
    "model_wrapper = finetune_self_ask(\n",
    "    model_name,\n",
    "    train_file,\n",
    "    valid_file,\n",
    "    checkpoint_filepath,\n",
    "    max_length,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    previous_checkpoint=prev_checkpoint\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2724,
     "status": "ok",
     "timestamp": 1689963756347,
     "user": {
      "displayName": "Richard Mathews",
      "userId": "15085444626849988348"
     },
     "user_tz": 300
    },
    "id": "13kvTCb5BkHu"
   },
   "outputs": [],
   "source": [
    "model_wrapper.save(\"models/flan-t5-small-direct.h5\", save_format=\"h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
