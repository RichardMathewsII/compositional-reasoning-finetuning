{"cells":[{"cell_type":"markdown","metadata":{"id":"9JSH4qAnLLUC"},"source":["# Training Demo\n","Demonstrate how to use training utilities to fine-tune an LLM."]},{"cell_type":"markdown","source":["## Working Directory and Libraries"],"metadata":{"id":"CO8CfM9O7sXZ"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"_R2UeFOnLLUH","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"error","timestamp":1701292407405,"user_tz":300,"elapsed":3061,"user":{"displayName":"Adam Weinberger","userId":"08337288854678718340"}},"outputId":"4ab03e05-c80b-41cf-997c-599bee583540"},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-31b14f72a71c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This cell will authenticate you and mount your Drive in the Colab.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["# This cell will authenticate you and mount your Drive in the Colab.\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os"],"metadata":{"id":"gJCWvMW67q-n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.chdir('/content/drive/MyDrive/MIDS/compositional-reasoning-finetuning')"],"metadata":{"id":"fq-01a7l752h"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iibm4YK8LLUG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700753543902,"user_tz":300,"elapsed":6927,"user":{"displayName":"Adam Weinberger","userId":"08337288854678718340"}},"outputId":"0c6280b1-c5bb-491c-9698-4db555f8fcbe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DZbmce7ULLUH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700753552928,"user_tz":300,"elapsed":9033,"user":{"displayName":"Adam Weinberger","userId":"08337288854678718340"}},"outputId":"6eefb6da-ccaf-46d7-dfda-5cf8a25e3f14"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}],"source":["!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AVNQGHKmLLUH"},"outputs":[],"source":["import os\n","import re\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","from transformers import T5Tokenizer, TFT5ForConditionalGeneration"]},{"cell_type":"markdown","metadata":{"id":"aNvln2Nl7ask"},"source":["# 2WikiMultiHopQA"]},{"cell_type":"markdown","metadata":{"id":"ohJ0QQc6LLUD"},"source":["## Load and format data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3HTbEALTLLUE"},"outputs":[],"source":["from data_loaders import load_FinetuningData\n","from training_utils import qa_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EklwIHiVLLUF"},"outputs":[],"source":["# Load data\n","data = load_FinetuningData(n_examples=5, split=\"dev\", strategy=\"direct\")\n","questions, answers = qa_split(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hsGEU18qLLUF","outputId":"0d1942f2-b11c-4ede-a1f4-3478879aa02b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700753571034,"user_tz":300,"elapsed":7,"user":{"displayName":"Adam Weinberger","userId":"08337288854678718340"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["['Facts:\\nFact #1: Vaettiya Madichu Kattu  is a 1998 Tamil film written and directed by K. Bhagyaraj.\\nFact #2: Krishnasaamy Bhagyaraj (born 7 January 1953) is an Indian director, actor, screenwriter, music director, producer and Politician active mainly in Tamil films.\\n\\nQuestion: What is the date of birth of the director of film Vaettiya Madichu Kattu?\\nAnswer:', 'Facts:\\nFact #1: She is the wife of Raila Odinga, the former Prime Minister of Kenya.\\nFact #2: Son of the first Vice President of Kenya, Jaramogi Oginga Odinga, he draws a large chunk of his support from various regions in Kenya, most notably the Coastal Region and his native former Nyanza Province.\\n\\nQuestion: Who is the father-in-law of Ida Odinga?\\nAnswer:', \"Facts:\\nFact #1: He was the eldest son of Bernhard I, Prince of Anhalt-Bernburg, by his wife Princess Sophie, daughter of King Abel of Denmark.\\nFact #2: He was the second son of Henry I, Count of Anhalt (who was elevated to the rank of prince in 1218), by his wife Irmgard, daughter of Hermann I, Landgrave of Thuringia.\\n\\nQuestion: Who is John I, Prince Of Anhalt-Bernburg's paternal grandfather?\\nAnswer:\", \"Facts:\\nFact #1: God's Will Be Done (Italian: Fiat voluntas dei) is a 1936 Italian comedy drama film directed by Amleto Palermi and starring Angelo Musco, María Denis and Sarah Ferrati.\\nFact #2: Riding on Air is a 1937 American film directed by Edward Sedgwick.\\nFact #3: Amleto Palermi( 11 July 1889 – 20 April 1941) was an Italian film director and screenwriter.\\nFact #4: Edward Sedgwick( November 7, 1889 – March 7, 1953) was an American film director, writer, actor and producer.\\n\\nQuestion: Are the directors of both films God'S Will Be Done and Riding On Air from the same country?\\nAnswer:\", \"Facts:\\nFact #1: The Squatter's Daughter is a 1933 Australian melodrama directed by Ken G. Hall and starring Jocelyn Howarth.\\nFact #2: Kenneth George Hall, AO, OBE (22 February 1901 – 8 February 1994), better known as Ken G. Hall, was an Australian film producer and director, considered one of the most important figures in the history of the Australian film industry.\\n\\nQuestion: When did the director of film The Squatter'S Daughter (1933 Film) die?\\nAnswer:\"]\n","['7 January 1953', 'Jaramogi Oginga Odinga', 'Henry I, Count of Anhalt', 'no', '8 February 1994']\n"]}],"source":["print(questions)\n","print(answers)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZC9JPlSNLLUF","outputId":"fa25b43a-2f1c-4c48-b3a4-577b358b4e7b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700753571034,"user_tz":300,"elapsed":4,"user":{"displayName":"Adam Weinberger","userId":"08337288854678718340"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Facts:\n","Fact #1: Vaettiya Madichu Kattu  is a 1998 Tamil film written and directed by K. Bhagyaraj.\n","Fact #2: Krishnasaamy Bhagyaraj (born 7 January 1953) is an Indian director, actor, screenwriter, music director, producer and Politician active mainly in Tamil films.\n","\n","Question: What is the date of birth of the director of film Vaettiya Madichu Kattu?\n","Answer:\n","7 January 1953\n","\n","Facts:\n","Fact #1: She is the wife of Raila Odinga, the former Prime Minister of Kenya.\n","Fact #2: Son of the first Vice President of Kenya, Jaramogi Oginga Odinga, he draws a large chunk of his support from various regions in Kenya, most notably the Coastal Region and his native former Nyanza Province.\n","\n","Question: Who is the father-in-law of Ida Odinga?\n","Answer:\n","Jaramogi Oginga Odinga\n","\n","Facts:\n","Fact #1: He was the eldest son of Bernhard I, Prince of Anhalt-Bernburg, by his wife Princess Sophie, daughter of King Abel of Denmark.\n","Fact #2: He was the second son of Henry I, Count of Anhalt (who was elevated to the rank of prince in 1218), by his wife Irmgard, daughter of Hermann I, Landgrave of Thuringia.\n","\n","Question: Who is John I, Prince Of Anhalt-Bernburg's paternal grandfather?\n","Answer:\n","Henry I, Count of Anhalt\n","\n","Facts:\n","Fact #1: God's Will Be Done (Italian: Fiat voluntas dei) is a 1936 Italian comedy drama film directed by Amleto Palermi and starring Angelo Musco, María Denis and Sarah Ferrati.\n","Fact #2: Riding on Air is a 1937 American film directed by Edward Sedgwick.\n","Fact #3: Amleto Palermi( 11 July 1889 – 20 April 1941) was an Italian film director and screenwriter.\n","Fact #4: Edward Sedgwick( November 7, 1889 – March 7, 1953) was an American film director, writer, actor and producer.\n","\n","Question: Are the directors of both films God'S Will Be Done and Riding On Air from the same country?\n","Answer:\n","no\n","\n","Facts:\n","Fact #1: The Squatter's Daughter is a 1933 Australian melodrama directed by Ken G. Hall and starring Jocelyn Howarth.\n","Fact #2: Kenneth George Hall, AO, OBE (22 February 1901 – 8 February 1994), better known as Ken G. Hall, was an Australian film producer and director, considered one of the most important figures in the history of the Australian film industry.\n","\n","Question: When did the director of film The Squatter'S Daughter (1933 Film) die?\n","Answer:\n","8 February 1994\n","\n"]}],"source":["# iterate over question answer pairs and print them\n","for question, answer in zip(questions, answers):\n","    print(question)\n","    print(answer)\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BiKEcmF1LLUG"},"outputs":[],"source":["# Load self-ask data\n","data = load_FinetuningData(n_examples=5, split=\"dev\", strategy=\"self_ask\")\n","questions, answers = qa_split(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LuOmQ17WLLUG","outputId":"8f0067d2-9e3b-4920-fa7a-ea2879b91a18","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700753572418,"user_tz":300,"elapsed":3,"user":{"displayName":"Adam Weinberger","userId":"08337288854678718340"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Examples:\n","START\n","Question: Who is Afonso Of Portugal, Lord Of Portalegre's paternal grandmother?\n","First break the reasoning down into intermediate questions, then provide an answer.\n","Intermediate question: What is the father of Afonso of Portugal?\n","Intermediate answer: Afonso III of Portugal\n","Intermediate question: Who is the mother of Afonso III of Portugal?\n","Intermediate answer: Urraca of Castile\n","So the answer is Urraca of Castile.\n","\n","END\n","\n","START\n","Question: Are both directors of films Undertow (1930 film) and Boomerang (1992 film) from the same country?\n","First break the reasoning down into intermediate questions, then provide an answer.\n","Intermediate question: Who is the director of Boomerang (1992 film)?\n","Intermediate answer: Reginald Hudlin\n","Intermediate question: Who is the director of Undertow (1930 film)?\n","Intermediate answer: Harry A. Pollard\n","Intermediate question: What is the country of citizenship of Reginald Hudlin?\n","Intermediate answer: American\n","Intermediate question: What is the country of citizenship of Harry A. Pollard?\n","Intermediate answer: American\n","So the answer is yes.\n","\n","END\n","\n","Facts:\n","Fact #1: Vaettiya Madichu Kattu  is a 1998 Tamil film written and directed by K. Bhagyaraj.\n","Fact #2: Krishnasaamy Bhagyaraj (born 7 January 1953) is an Indian director, actor, screenwriter, music director, producer and Politician active mainly in Tamil films.\n","\n","Question: What is the date of birth of the director of film Vaettiya Madichu Kattu?\n","First break the reasoning down into intermediate questions, then provide an answer.\n","\n","Intermediate question: Who is the director of Vaettiya Madichu Kattu?\n","Intermediate answer: K. Bhagyaraj\n","Intermediate question: When is the date of birth of K. Bhagyaraj?\n","Intermediate answer: 7 January 1953\n","So the final answer is 7 January 1953.\n","\n"]}],"source":["print(questions[0])\n","print(answers[0])"]},{"cell_type":"markdown","metadata":{"id":"1Kk78TidLLUG"},"source":["## Demo of MultihopQADataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mkyXQVELLLUH","colab":{"base_uri":"https://localhost:8080/","height":373,"referenced_widgets":["c2842d26093247d1a9e3a750494f7bdb","c485d723b55e4ab8ae7596b8a824f3a8","a87355af67cc4e5baf0b915788a32d28","769a2bdeac6f43e4b54cb081bbeea0c1","a630fcc69c6e412a888f5f69c7443179","1f9f144274e6429dbad7e2dcf39123b6","e5b64320dc174eafb813177554383650","64b9ba6ef4ce420e9ac0fddf5eef41f7","6648f55315d6400288fa5757c3f6a342","eeb6248d36c54a36b16c7dfde77d9ce4","562656ec7c3444c0a967b0fea71bf099","99824f67d76241228c61499370282c6d","93014527a8fc40089d37d61c8bca4125","ed8292c6bb0a493985c79a298aff2c19","e97dd15e8b954503b0eb28fd90c5eee5","b204cc29d52c4e7fa0dc185833546a03","ccefb42af3d44c72bf74a9f45f5baa5b","eb5c85d7ee124886b15db27de14fa675","a8664f7dc2d3408f9d0d0be95e3ae25e","52ecb20e2d1b406abada340307db1d8f","03d6f8e9493c4347bf897776ea702b1e","0e6ee0e450a54d81806dbcb5b0cbb687","03630dc3a85643d89767c54efd067e6c","f6d889a8c0234473ac8d1ca42fc6e0c3","3f92beee4e504d99951bd9b655e8112d","f1282f6cdfc64e5c86e0dc027a6d3fce","6e086914357b495ea7f6aa1524679f3a","84663a878a854bb1b0d4404fce5d0f20","f54007575870435c86d969539a14465a","1c3472e00ad9472a8fdb3ea42cde1ae4","c1e0bb3e471541c796acb0a7d15a617b","8a4522fa85aa48e49c448df458eab13c","8673c0aee0d243ca8f3a936644cb0dcd","f562360438fa4bb1b5ae26c54ecb77ed","acf2763938b34693854eb4623f9ab4b1","756387012f654b5bb3d05ce4fdcfacf2","ff7f8d99c6c9467bb8880ca0ba0e8741","2ac1e2b94a6e47ffbe4945f31a9e01f0","a82929b678ba4104a998c83dd5c11e47","b62d3d4886f14c0ea1cbed7836b71ee8","3e16a9c59c7e4350813fe9e406aeb90c","b5c10698cec648e3a876bd9b7db07028","cdb8ee7c10934806999f060ad570c07c","de700324713d43a7b244e7b32612ddb7"]},"executionInfo":{"status":"ok","timestamp":1700753596558,"user_tz":300,"elapsed":24141,"user":{"displayName":"Adam Weinberger","userId":"08337288854678718340"}},"outputId":"4cdf9b8e-cbd1-4b54-9fc2-5007edffeb42"},"outputs":[{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2842d26093247d1a9e3a750494f7bdb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99824f67d76241228c61499370282c6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03630dc3a85643d89767c54efd067e6c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:240: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f562360438fa4bb1b5ae26c54ecb77ed"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n","\n","All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"]}],"source":["# Load the pretrained tensorflow model\n","\n","model_name = 't5-base'\n","t5_tokenizer = T5Tokenizer.from_pretrained(model_name)\n","t5_model = TFT5ForConditionalGeneration.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3l2VLGQLLpRP"},"outputs":[],"source":["train_file = 'data/FinetuningData/self_ask_train-answer_first=False-random_facts=False.json'\n","valid_file = 'data/FinetuningData/self_ask_dev-answer_first=False-random_facts=False.json'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uStzs7NIL0yM"},"outputs":[],"source":["n_train_pairs = 154876\n","n_valid_pairs = 12576"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F9sICT5VLLUI"},"outputs":[],"source":["import json\n","\n","f_train = open(train_file)\n","f_valid = open(valid_file)\n","\n","js_train = json.load(f_train)\n","js_valid = json.load(f_valid)\n","\n","# Close JSON file\n","f_train.close()\n","f_valid.close()\n","\n","n_train_pairs = len(js_train) #154876\n","n_valid_pairs = len(js_valid) #12576\n","\n","del js_train\n","del js_valid"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vJQ2MhuiLLUI"},"outputs":[],"source":["# Create the data generators for train and validation data, tensorflow version\n","from training_utils import MultihopQADataGenerator\n","\n","max_length = 32\n","max_length = 512\n","batch_size = 16\n","\n","train_data_generator = MultihopQADataGenerator(\n","    tokenizer=t5_tokenizer,\n","    model=t5_model,\n","    n_examples=n_train_pairs,\n","    data_filename=train_file,\n","    max_length=max_length,\n","    batch_size=batch_size\n",")\n","\n","valid_data_generator = MultihopQADataGenerator(\n","    tokenizer=t5_tokenizer,\n","    model=t5_model,\n","    n_examples=n_valid_pairs,\n","    data_filename=valid_file,\n","    max_length=max_length,\n","    batch_size=batch_size\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kUOsacBcLLUI"},"outputs":[],"source":["def build_t5_training_wrapper_model(t5_model, max_length):\n","    input_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='input_ids')\n","    attention_mask = layers.Input(shape=(max_length), dtype=tf.int32, name='attention_mask')\n","    decoder_input_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='labels')\n","\n","    t5_logits = t5_model(input_ids, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids)[0]\n","\n","    model = tf.keras.models.Model(inputs=[input_ids, attention_mask, decoder_input_ids],\n","                                  outputs=[t5_logits])\n","    model.compile(optimizer=tf.keras.optimizers.Adam(),\n","                  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                  metrics=['accuracy'])\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4cglZF2rLLUJ"},"outputs":[],"source":["model_wrapper = build_t5_training_wrapper_model(t5_model, max_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q6DNNn9kLLUJ"},"outputs":[],"source":["# As in the first notebook, we should add a model checkpoint callback to save\n","# the trained model weights after each epoch. Edit the filepath to where\n","# you want to save the weights in your own Drive\n","\n","# checkpoint_dir = 'drive/MyDrive/266/data/self_ask/model_checkpoints/'\n","# checkpoint_dir = 'drive/MyDrive/projects/compositional-reasoning-finetuning/checkpoints/t5-base-self-ask/' # richard\n","checkpoint_filepath = os.getcwd() + '/checkpoints/{model_name}-self-ask/t5_direct_weights.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eLcgtXD5LLUJ","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1700753780659,"user_tz":300,"elapsed":79745,"user":{"displayName":"Adam Weinberger","userId":"08337288854678718340"}},"outputId":"15644918-2715-4aa8-d5cc-b4ebe87bca09"},"outputs":[{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-4bd3e17a496e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model checkpoint callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model_wrapper.fit(train_data_generator,\n\u001b[0m\u001b[1;32m      5\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node model/tft5_for_conditional_generation/encoder/block_._10/layer_._0/SelfAttention/Softmax defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-22-4bd3e17a496e>\", line 4, in <cell line: 4>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1126, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 589, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 589, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1298, in run_call_with_unpacked_inputs\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 1339, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 1340, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\", line 1298, in run_call_with_unpacked_inputs\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 775, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 778, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 567, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 457, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_tf_t5.py\", line 407, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/tf_utils.py\", line 70, in stable_softmax\n\nOOM when allocating tensor with shape[16,12,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/tft5_for_conditional_generation/encoder/block_._10/layer_._0/SelfAttention/Softmax}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_63701]"]}],"source":["# Now call .fit on the model_wrapper, passing in the data generators and the\n","# model checkpoint callback\n","\n","model_wrapper.fit(train_data_generator,\n","                  validation_data=valid_data_generator,\n","                  epochs=1,\n","                  callbacks=[model_checkpoint_callback])"]},{"cell_type":"markdown","metadata":{"id":"toPdU6Z8Z-sr"},"source":["## Standardized function call for all models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mpV_ApGFQxSd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700753980718,"user_tz":300,"elapsed":6376,"user":{"displayName":"Adam Weinberger","userId":"08337288854678718340"}},"outputId":"4a621868-c7fa-47ce-ff15-a335c9713c80"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yjbi4156StfI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700753989804,"user_tz":300,"elapsed":9089,"user":{"displayName":"Adam Weinberger","userId":"08337288854678718340"}},"outputId":"5e656c6a-1036-47f9-d099-e0350674db2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"]}],"source":["!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f2Q2daEoQq1e"},"outputs":[],"source":["import os\n","import re\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","from transformers import T5Tokenizer, TFT5ForConditionalGeneration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4v8wQbPLOF5Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700753993527,"user_tz":300,"elapsed":3725,"user":{"displayName":"Adam Weinberger","userId":"08337288854678718340"}},"outputId":"14d3c120-94a0-4944-ec83-ae64fc192a90"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJaLXmR0Oder"},"outputs":[],"source":["os.chdir('/content/drive/MyDrive/MIDS/compositional-reasoning-finetuning')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CyFSd1hHZ-sr"},"outputs":[],"source":["from training_utils import finetune_self_ask\n","import json\n","\n","# model_name\n","model_name = 't5-base'\n","\n","# traing and validation file path\n","#train_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_train.json'\n","#valid_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_dev.json'\n","train_file = 'data/finetuning/self_ask_train.json'\n","valid_file = 'data/finetuning/self_ask_dev.json'\n","\n","# path and file name for checkpoint\n","checkpoint_dir = 'model_checkpoints/'\n","checkpoint_filepath = checkpoint_dir + model_name + '_self_ask_weights.{epoch:02d}-{batch:00005d}.hdf5'\n","\n","# hyper parameters\n","max_length = 600\n","batch_size = 16\n","epochs = 2\n","\n","model_wrapper = finetune_self_ask(model_name, train_file, valid_file, checkpoint_filepath, max_length, batch_size, epochs)"]},{"cell_type":"markdown","metadata":{"id":"SOAo66HG7asp"},"source":["## Function call to filter json by token size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7JyPSe17asp"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wwLRQc1K7asp"},"outputs":[],"source":["%cd drive/MyDrive/266/compositional_reasoning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VAnsUZwX7asp"},"outputs":[],"source":["train_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_train.json'\n","valid_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_dev.json'\n","token_size = 470"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XFoJ27xW7asp"},"outputs":[],"source":["filter_token_size(train_file, valid_file, token_size)"]},{"cell_type":"markdown","metadata":{"id":"oOh6cFNC7asp"},"source":["## Load previously saved checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cL0tW4W57asp"},"outputs":[],"source":["from training_utils import finetune_self_ask\n","import json\n","\n","# model_name\n","model_name = 't5-small'\n","\n","# traing and validation file path\n","train_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_train_300.json'\n","valid_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_dev_300.json'\n","#train_file = 'data/finetuning/self_ask_train_480.json'\n","#valid_file = 'data/finetuning/self_ask_dev_480.json'\n","\n","previous_checkpoint = \"./model_checkpoints/t5-small_v100_self_ask_300_weights.02-00704.hdf5\"\n","\n","# path and file name for checkpoint\n","checkpoint_dir = '/content/drive/MyDrive/266/compositional_reasoning/model_checkpoints/'\n","checkpoint_filepath = checkpoint_dir + model_name + '_v100_self_ask_300_weights.{epoch:02d}-{batch:00005d}.hdf5'\n","\n","# hyper parameters\n","max_length = 300\n","batch_size = 32\n","epochs = 2\n","\n","model_wrapper = finetune_self_ask(model_name, train_file, valid_file, checkpoint_filepath, max_length, batch_size, epochs, previous_checkpoint)"]},{"cell_type":"markdown","metadata":{"id":"JYHjLzCj7asp"},"source":["# HotPotQA"]},{"cell_type":"markdown","metadata":{"id":"VLNRxC0Q7ast"},"source":["## Load and format data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p8_JildU7ast"},"outputs":[],"source":["from data_loaders import load_FinetuningData\n","from training_utils import qa_split, tokenize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dll_X-oa7ast"},"outputs":[],"source":["# Load data\n","data = load_FinetuningData(n_examples=5, split=\"dev\", strategy=\"direct\")\n","questions, answers = qa_split(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m91wWhX07ast"},"outputs":[],"source":["print(questions)\n","print(answers)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OKARtr47ast"},"outputs":[],"source":["# iterate over question answer pairs and print them\n","for question, answer in zip(questions, answers):\n","    print(question)\n","    print(answer)\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-XV1eVdU7asu"},"outputs":[],"source":["# Load self-ask data\n","data = load_FinetuningData(n_examples=5, split=\"dev\", strategy=\"self_ask\")\n","questions, answers = qa_split(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TLjbVSo87asu"},"outputs":[],"source":["print(questions[0])\n","print(answers[0])"]},{"cell_type":"markdown","metadata":{"id":"XYlrJFbg7asu"},"source":["## Demo of MultihopQADataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gNbRN8cB7asu"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TiGqcvWE7asu"},"outputs":[],"source":["!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sWyXTWbh7asu"},"outputs":[],"source":["import os\n","import re\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","from transformers import T5Tokenizer, TFT5ForConditionalGeneration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cGVzmgEp7asu"},"outputs":[],"source":["# This cell will authenticate you and mount your Drive in the Colab.\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4j_r9pQc7asu"},"outputs":[],"source":["# Load the pretrained tensorflow model\n","\n","model_name = 't5-base'\n","t5_tokenizer = T5Tokenizer.from_pretrained(model_name)\n","t5_model = TFT5ForConditionalGeneration.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CZ3o5Fdi7asu"},"outputs":[],"source":["# richard\n","train_file = 'data/FinetuningData/self_ask_train.json'\n","valid_file = 'data/FinetuningData/self_ask_dev.json'\n","\n","%cd drive/MyDrive/projects/compositional-reasoning-finetuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJoOjlb47asu"},"outputs":[],"source":["n_train_pairs = 154876\n","n_valid_pairs = 12576"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7tMhcxNQ7asu"},"outputs":[],"source":["train_file = 'drive/MyDrive/266/data/self_ask_train.json'\n","valid_file = 'drive/MyDrive/266/data/self_ask_dev.json'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9qJ1XHj7asu"},"outputs":[],"source":["import json\n","\n","f_train = open('drive/MyDrive/266/data/self_ask_train.json')\n","f_valid = open('drive/MyDrive/266/data/self_ask_dev.json')\n","\n","js_train = json.load(f_train)\n","js_valid = json.load(f_valid)\n","\n","# Close JSON file\n","f_train.close()\n","f_valid.close()\n","\n","n_train_pairs = len(js_train) #154876\n","n_valid_pairs = len(js_valid) #12576\n","\n","del js_train\n","del js_valid"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vAGjJ90K7asu"},"outputs":[],"source":["# Create the data generators for train and validation data, tensorflow version\n","from training_utils import MultihopQADataGenerator\n","\n","max_length = 32\n","max_length = 512\n","batch_size = 16\n","\n","train_data_generator = MultihopQADataGenerator(\n","    tokenizer=t5_tokenizer,\n","    model=t5_model,\n","    n_examples=n_train_pairs,\n","    data_filename=train_file,\n","    max_length=max_length,\n","    batch_size=batch_size\n",")\n","\n","valid_data_generator = MultihopQADataGenerator(\n","    tokenizer=t5_tokenizer,\n","    model=t5_model,\n","    n_examples=n_valid_pairs,\n","    data_filename=valid_file,\n","    max_length=max_length,\n","    batch_size=batch_size\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AJIJP-pF7asv"},"outputs":[],"source":["def build_t5_training_wrapper_model(t5_model, max_length):\n","    input_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='input_ids')\n","    attention_mask = layers.Input(shape=(max_length), dtype=tf.int32, name='attention_mask')\n","    decoder_input_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='labels')\n","\n","    t5_logits = t5_model(input_ids, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids)[0]\n","\n","    model = tf.keras.models.Model(inputs=[input_ids, attention_mask, decoder_input_ids],\n","                                  outputs=[t5_logits])\n","    model.compile(optimizer=tf.keras.optimizers.Adam(),\n","                  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                  metrics=['accuracy'])\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pBCuNVSf7asv"},"outputs":[],"source":["model_wrapper = build_t5_training_wrapper_model(t5_model, max_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wmd08tRX7asv"},"outputs":[],"source":["# As in the first notebook, we should add a model checkpoint callback to save\n","# the trained model weights after each epoch. Edit the filepath to where\n","# you want to save the weights in your own Drive\n","\n","# checkpoint_dir = 'drive/MyDrive/266/data/self_ask/model_checkpoints/'\n","checkpoint_dir = 'drive/MyDrive/projects/compositional-reasoning-finetuning/checkpoints/t5-base-self-ask/' # richard\n","checkpoint_filepath = checkpoint_dir + 't5_direct_weights.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OWSSco_X7asv"},"outputs":[],"source":["# Now call .fit on the model_wrapper, passing in the data generators and the\n","# model checkpoint callback\n","\n","model_wrapper.fit(train_data_generator,\n","                  validation_data=valid_data_generator,\n","                  epochs=1,\n","                  callbacks=[model_checkpoint_callback])"]},{"cell_type":"markdown","metadata":{"id":"86IMo9eP7asv"},"source":["## Standardized function call for all models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gLVUOkka7asv"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RzvrT2iJ7asv"},"outputs":[],"source":["!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQe5bfbD7asv"},"outputs":[],"source":["import os\n","import re\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","from transformers import T5Tokenizer, TFT5ForConditionalGeneration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZKnOYpe7asv"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hGU8ksRp7asv"},"outputs":[],"source":["%cd drive/MyDrive/266/compositional_reasoning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jw89RNSy7asv"},"outputs":[],"source":["from training_utils import finetune_self_ask\n","import json\n","\n","# model_name\n","model_name = 't5-base'\n","\n","# traing and validation file path\n","#train_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_train.json'\n","#valid_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_dev.json'\n","train_file = 'data/finetuning/self_ask_train.json'\n","valid_file = 'data/finetuning/self_ask_dev.json'\n","\n","# path and file name for checkpoint\n","checkpoint_dir = 'model_checkpoints/'\n","checkpoint_filepath = checkpoint_dir + model_name + '_self_ask_weights.{epoch:02d}-{batch:00005d}.hdf5'\n","\n","# hyper parameters\n","max_length = 600\n","batch_size = 16\n","epochs = 2\n","\n","model_wrapper = finetune_self_ask(model_name, train_file, valid_file, checkpoint_filepath, max_length, batch_size, epochs)"]},{"cell_type":"markdown","metadata":{"id":"hhUMnoJr7asv"},"source":["## Function call to filter json by token size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vfeZ-NR77asv"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W8HH_Uy17asv"},"outputs":[],"source":["%cd drive/MyDrive/266/compositional_reasoning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DZNvFStf7asw"},"outputs":[],"source":["train_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_train.json'\n","valid_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_dev.json'\n","token_size = 470"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C71PmdyA7asw"},"outputs":[],"source":["filter_token_size(train_file, valid_file, token_size)"]},{"cell_type":"markdown","metadata":{"id":"fAYVUT2e7asw"},"source":["## Load previously saved checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YuuJJJ4o7asw"},"outputs":[],"source":["from training_utils import finetune_self_ask\n","import json\n","\n","# model_name\n","model_name = 't5-small'\n","\n","# traing and validation file path\n","train_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_train_300.json'\n","valid_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_dev_300.json'\n","#train_file = 'data/finetuning/self_ask_train_480.json'\n","#valid_file = 'data/finetuning/self_ask_dev_480.json'\n","\n","previous_checkpoint = \"./model_checkpoints/t5-small_v100_self_ask_300_weights.02-00704.hdf5\"\n","\n","# path and file name for checkpoint\n","checkpoint_dir = '/content/drive/MyDrive/266/compositional_reasoning/model_checkpoints/'\n","checkpoint_filepath = checkpoint_dir + model_name + '_v100_self_ask_300_weights.{epoch:02d}-{batch:00005d}.hdf5'\n","\n","# hyper parameters\n","max_length = 300\n","batch_size = 32\n","epochs = 2\n","\n","model_wrapper = finetune_self_ask(model_name, train_file, valid_file, checkpoint_filepath, max_length, batch_size, epochs, previous_checkpoint)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c2842d26093247d1a9e3a750494f7bdb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c485d723b55e4ab8ae7596b8a824f3a8","IPY_MODEL_a87355af67cc4e5baf0b915788a32d28","IPY_MODEL_769a2bdeac6f43e4b54cb081bbeea0c1"],"layout":"IPY_MODEL_a630fcc69c6e412a888f5f69c7443179"}},"c485d723b55e4ab8ae7596b8a824f3a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f9f144274e6429dbad7e2dcf39123b6","placeholder":"​","style":"IPY_MODEL_e5b64320dc174eafb813177554383650","value":"spiece.model: 100%"}},"a87355af67cc4e5baf0b915788a32d28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_64b9ba6ef4ce420e9ac0fddf5eef41f7","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6648f55315d6400288fa5757c3f6a342","value":791656}},"769a2bdeac6f43e4b54cb081bbeea0c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eeb6248d36c54a36b16c7dfde77d9ce4","placeholder":"​","style":"IPY_MODEL_562656ec7c3444c0a967b0fea71bf099","value":" 792k/792k [00:00&lt;00:00, 4.07MB/s]"}},"a630fcc69c6e412a888f5f69c7443179":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f9f144274e6429dbad7e2dcf39123b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5b64320dc174eafb813177554383650":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64b9ba6ef4ce420e9ac0fddf5eef41f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6648f55315d6400288fa5757c3f6a342":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eeb6248d36c54a36b16c7dfde77d9ce4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"562656ec7c3444c0a967b0fea71bf099":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99824f67d76241228c61499370282c6d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93014527a8fc40089d37d61c8bca4125","IPY_MODEL_ed8292c6bb0a493985c79a298aff2c19","IPY_MODEL_e97dd15e8b954503b0eb28fd90c5eee5"],"layout":"IPY_MODEL_b204cc29d52c4e7fa0dc185833546a03"}},"93014527a8fc40089d37d61c8bca4125":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ccefb42af3d44c72bf74a9f45f5baa5b","placeholder":"​","style":"IPY_MODEL_eb5c85d7ee124886b15db27de14fa675","value":"tokenizer.json: 100%"}},"ed8292c6bb0a493985c79a298aff2c19":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8664f7dc2d3408f9d0d0be95e3ae25e","max":1389353,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52ecb20e2d1b406abada340307db1d8f","value":1389353}},"e97dd15e8b954503b0eb28fd90c5eee5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03d6f8e9493c4347bf897776ea702b1e","placeholder":"​","style":"IPY_MODEL_0e6ee0e450a54d81806dbcb5b0cbb687","value":" 1.39M/1.39M [00:00&lt;00:00, 8.21MB/s]"}},"b204cc29d52c4e7fa0dc185833546a03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccefb42af3d44c72bf74a9f45f5baa5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb5c85d7ee124886b15db27de14fa675":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8664f7dc2d3408f9d0d0be95e3ae25e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52ecb20e2d1b406abada340307db1d8f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"03d6f8e9493c4347bf897776ea702b1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e6ee0e450a54d81806dbcb5b0cbb687":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03630dc3a85643d89767c54efd067e6c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6d889a8c0234473ac8d1ca42fc6e0c3","IPY_MODEL_3f92beee4e504d99951bd9b655e8112d","IPY_MODEL_f1282f6cdfc64e5c86e0dc027a6d3fce"],"layout":"IPY_MODEL_6e086914357b495ea7f6aa1524679f3a"}},"f6d889a8c0234473ac8d1ca42fc6e0c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84663a878a854bb1b0d4404fce5d0f20","placeholder":"​","style":"IPY_MODEL_f54007575870435c86d969539a14465a","value":"config.json: 100%"}},"3f92beee4e504d99951bd9b655e8112d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c3472e00ad9472a8fdb3ea42cde1ae4","max":1208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1e0bb3e471541c796acb0a7d15a617b","value":1208}},"f1282f6cdfc64e5c86e0dc027a6d3fce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a4522fa85aa48e49c448df458eab13c","placeholder":"​","style":"IPY_MODEL_8673c0aee0d243ca8f3a936644cb0dcd","value":" 1.21k/1.21k [00:00&lt;00:00, 51.0kB/s]"}},"6e086914357b495ea7f6aa1524679f3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84663a878a854bb1b0d4404fce5d0f20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f54007575870435c86d969539a14465a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c3472e00ad9472a8fdb3ea42cde1ae4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1e0bb3e471541c796acb0a7d15a617b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a4522fa85aa48e49c448df458eab13c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8673c0aee0d243ca8f3a936644cb0dcd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f562360438fa4bb1b5ae26c54ecb77ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_acf2763938b34693854eb4623f9ab4b1","IPY_MODEL_756387012f654b5bb3d05ce4fdcfacf2","IPY_MODEL_ff7f8d99c6c9467bb8880ca0ba0e8741"],"layout":"IPY_MODEL_2ac1e2b94a6e47ffbe4945f31a9e01f0"}},"acf2763938b34693854eb4623f9ab4b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a82929b678ba4104a998c83dd5c11e47","placeholder":"​","style":"IPY_MODEL_b62d3d4886f14c0ea1cbed7836b71ee8","value":"model.safetensors: 100%"}},"756387012f654b5bb3d05ce4fdcfacf2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e16a9c59c7e4350813fe9e406aeb90c","max":891646390,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5c10698cec648e3a876bd9b7db07028","value":891646390}},"ff7f8d99c6c9467bb8880ca0ba0e8741":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdb8ee7c10934806999f060ad570c07c","placeholder":"​","style":"IPY_MODEL_de700324713d43a7b244e7b32612ddb7","value":" 892M/892M [00:08&lt;00:00, 101MB/s]"}},"2ac1e2b94a6e47ffbe4945f31a9e01f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a82929b678ba4104a998c83dd5c11e47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b62d3d4886f14c0ea1cbed7836b71ee8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e16a9c59c7e4350813fe9e406aeb90c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5c10698cec648e3a876bd9b7db07028":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cdb8ee7c10934806999f060ad570c07c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de700324713d43a7b244e7b32612ddb7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}