{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JSH4qAnLLUC"
   },
   "source": [
    "# Training Demo\n",
    "Demonstrate how to use training utilities to fine-tune an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2WikiMultiHopQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohJ0QQc6LLUD"
   },
   "source": [
    "## Load and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "3HTbEALTLLUE",
    "outputId": "375d1703-24a7-431f-ac11-17e2967a30cd"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdata_loaders\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_FinetuningData\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtraining_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m qa_split, tokenize\n",
      "File \u001B[0;32m~/MIDS/compositional-reasoning-finetuning/training_utils.py:7\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m layers\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from data_loaders import load_FinetuningData\n",
    "from training_utils import qa_split, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EklwIHiVLLUF"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_FinetuningData(n_examples=5, split=\"dev\", strategy=\"direct\")\n",
    "questions, answers = qa_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsGEU18qLLUF",
    "outputId": "5665b107-6602-4999-c77a-a14850044f22"
   },
   "outputs": [],
   "source": [
    "print(questions)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZC9JPlSNLLUF",
    "outputId": "e699dadc-3535-4dd4-9f03-197f78ea2cf4"
   },
   "outputs": [],
   "source": [
    "# iterate over question answer pairs and print them\n",
    "for question, answer in zip(questions, answers):\n",
    "    print(question)\n",
    "    print(answer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BiKEcmF1LLUG"
   },
   "outputs": [],
   "source": [
    "# Load self-ask data\n",
    "data = load_FinetuningData(n_examples=5, split=\"dev\", strategy=\"self_ask\")\n",
    "questions, answers = qa_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuOmQ17WLLUG",
    "outputId": "af5f4610-8679-4e65-d1f1-5923efab320d"
   },
   "outputs": [],
   "source": [
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Kk78TidLLUG"
   },
   "source": [
    "## Demo of MultihopQADataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iibm4YK8LLUG",
    "outputId": "7f008e53-b15b-4d94-d392-466504ab1440"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DZbmce7ULLUH",
    "outputId": "dd5c5a88-1d84-4e6b-f724-839b4c40dfc6"
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AVNQGHKmLLUH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_R2UeFOnLLUH",
    "outputId": "d1660227-ac0c-4544-8bab-bbe934932558"
   },
   "outputs": [],
   "source": [
    "# This cell will authenticate you and mount your Drive in the Colab.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311,
     "referenced_widgets": [
      "0304f50d44f144158598804e3671318d",
      "4ae3959fbfc74b99a7ea76d350ba7ff6",
      "3687bdb5005f432a82174c0ad05e6b09",
      "62067fae55c74772a26f8150c1c41661",
      "6ba4de3e80f84cd3b27d709a2f67c395",
      "aca67aa5f66c499da7af7d979ef818c9",
      "249a829372e4402ca5428c6cf570de4f",
      "349561b24a7344de8af29f3009077fb0",
      "cee522e246e04de68ed667a3aab92c64",
      "ec0890e0e25a471dacaec4778565ec86",
      "a187a9f0149040d9a758acfd4972d91a",
      "2a8982922b6141b889ed07a1df582618",
      "e3d18e339e4d4af5971dfe241f013ddd",
      "d469b15fa7ae465e82c11929baf072c3",
      "ec894fc0b7664a6fac216fc961a24f1a",
      "1d057b532c4d402fa0540fa26df2abce",
      "931fb586c3194a61ae1c89576ee0e4b9",
      "67eb9a1604c0465ca0e2f75ca786b1db",
      "71e4cf59d7304072824ef232a0ee7460",
      "4534dbabd5ac4ca6b36b55cd24e1c503",
      "98d51394b4c04b419cda7a26b39772a7",
      "0ca43904714541ee85462930a566f14a",
      "83595f1f310b4e2bb9089297954893d9",
      "b870ce76f0ff4c05bf5fb46479b05d97",
      "ccc5189837f1457790a2634537e2f5cf",
      "dba60e0cfa174ac4b31418f44f0c86b8",
      "fcc76cc4f6c246c18431146e251ac1cb",
      "4bfbedd64e324a5c9c0bd85751c8d8bf",
      "bcb890f8ecb44b5784c224df1cc4ab10",
      "31ea5200727343419cb06033668773c6",
      "8e840a658be74d4ca9373250e8974628",
      "72626abaf3524ef983336b86ffdec4d2",
      "bd1050dc36b442d38e1ce63fe0c5126f"
     ]
    },
    "id": "mkyXQVELLLUH",
    "outputId": "69024f00-c334-4f52-c0aa-d8b3e5b4b52f"
   },
   "outputs": [],
   "source": [
    "# Load the pretrained tensorflow model\n",
    "\n",
    "model_name = 't5-base'\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "t5_model = TFT5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3l2VLGQLLpRP"
   },
   "outputs": [],
   "source": [
    "# richard\n",
    "train_file = 'data/FinetuningData/self_ask_train.json'\n",
    "valid_file = 'data/FinetuningData/self_ask_dev.json'\n",
    "\n",
    "%cd drive/MyDrive/projects/compositional-reasoning-finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uStzs7NIL0yM"
   },
   "outputs": [],
   "source": [
    "n_train_pairs = 154876\n",
    "n_valid_pairs = 12576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QgkJG561LLUI"
   },
   "outputs": [],
   "source": [
    "train_file = 'drive/MyDrive/266/data/self_ask_train.json'\n",
    "valid_file = 'drive/MyDrive/266/data/self_ask_dev.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9sICT5VLLUI"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f_train = open('drive/MyDrive/266/data/self_ask_train.json')\n",
    "f_valid = open('drive/MyDrive/266/data/self_ask_dev.json')\n",
    "\n",
    "js_train = json.load(f_train)\n",
    "js_valid = json.load(f_valid)\n",
    "\n",
    "# Close JSON file\n",
    "f_train.close()\n",
    "f_valid.close()\n",
    "\n",
    "n_train_pairs = len(js_train) #154876\n",
    "n_valid_pairs = len(js_valid) #12576\n",
    "\n",
    "del js_train\n",
    "del js_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJQ2MhuiLLUI"
   },
   "outputs": [],
   "source": [
    "# Create the data generators for train and validation data, tensorflow version\n",
    "from training_utils import MultihopQADataGenerator\n",
    "\n",
    "max_length = 32\n",
    "max_length = 512\n",
    "batch_size = 16\n",
    "\n",
    "train_data_generator = MultihopQADataGenerator(\n",
    "    tokenizer=t5_tokenizer,\n",
    "    model=t5_model,\n",
    "    n_examples=n_train_pairs,\n",
    "    data_filename=train_file,\n",
    "    max_length=max_length,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "valid_data_generator = MultihopQADataGenerator(\n",
    "    tokenizer=t5_tokenizer,\n",
    "    model=t5_model,\n",
    "    n_examples=n_valid_pairs,\n",
    "    data_filename=valid_file,\n",
    "    max_length=max_length,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUOsacBcLLUI"
   },
   "outputs": [],
   "source": [
    "def build_t5_training_wrapper_model(t5_model, max_length):\n",
    "    input_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = layers.Input(shape=(max_length), dtype=tf.int32, name='attention_mask')\n",
    "    decoder_input_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='labels')\n",
    "\n",
    "    t5_logits = t5_model(input_ids, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids)[0]\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[input_ids, attention_mask, decoder_input_ids],\n",
    "                                  outputs=[t5_logits])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cglZF2rLLUJ"
   },
   "outputs": [],
   "source": [
    "model_wrapper = build_t5_training_wrapper_model(t5_model, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6DNNn9kLLUJ"
   },
   "outputs": [],
   "source": [
    "# As in the first notebook, we should add a model checkpoint callback to save\n",
    "# the trained model weights after each epoch. Edit the filepath to where\n",
    "# you want to save the weights in your own Drive\n",
    "\n",
    "# checkpoint_dir = 'drive/MyDrive/266/data/self_ask/model_checkpoints/'\n",
    "checkpoint_dir = 'drive/MyDrive/projects/compositional-reasoning-finetuning/checkpoints/t5-base-self-ask/' # richard\n",
    "checkpoint_filepath = checkpoint_dir + 't5_direct_weights.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "eLcgtXD5LLUJ",
    "outputId": "7d943358-84d0-4bef-d3d3-f62f3f8e8588"
   },
   "outputs": [],
   "source": [
    "# Now call .fit on the model_wrapper, passing in the data generators and the\n",
    "# model checkpoint callback\n",
    "\n",
    "model_wrapper.fit(train_data_generator,\n",
    "                  validation_data=valid_data_generator,\n",
    "                  epochs=1,\n",
    "                  callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toPdU6Z8Z-sr"
   },
   "source": [
    "## Standardized function call for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpV_ApGFQxSd",
    "outputId": "a6589042-eaad-4c9a-c34c-c9464dfa684d"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yjbi4156StfI",
    "outputId": "f96114a5-d5c0-4d2a-bd3e-b7596178c111"
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2Q2daEoQq1e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4v8wQbPLOF5Q",
    "outputId": "04c10453-b4c5-49e5-9770-e08b3a4bb1f7"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJaLXmR0Oder",
    "outputId": "77dd22eb-4b70-44c8-f087-f61117d27054"
   },
   "outputs": [],
   "source": [
    "%cd drive/MyDrive/266/compositional_reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "CyFSd1hHZ-sr",
    "outputId": "42ea4bd8-020f-4928-9900-a0782397bee2"
   },
   "outputs": [],
   "source": [
    "from training_utils import finetune_self_ask\n",
    "import json\n",
    "\n",
    "# model_name\n",
    "model_name = 't5-base'\n",
    "\n",
    "# traing and validation file path\n",
    "#train_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_train.json'\n",
    "#valid_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_dev.json'\n",
    "train_file = 'data/finetuning/self_ask_train.json'\n",
    "valid_file = 'data/finetuning/self_ask_dev.json'\n",
    "\n",
    "# path and file name for checkpoint\n",
    "checkpoint_dir = 'model_checkpoints/'\n",
    "checkpoint_filepath = checkpoint_dir + model_name + '_self_ask_weights.{epoch:02d}-{batch:00005d}.hdf5'\n",
    "\n",
    "# hyper parameters\n",
    "max_length = 600\n",
    "batch_size = 16\n",
    "epochs = 2\n",
    "\n",
    "model_wrapper = finetune_self_ask(model_name, train_file, valid_file, checkpoint_filepath, max_length, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function call to filter json by token size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd drive/MyDrive/266/compositional_reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_train.json'\n",
    "valid_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_dev.json'\n",
    "token_size = 470"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_token_size(train_file, valid_file, token_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previously saved checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_utils import finetune_self_ask\n",
    "import json\n",
    "\n",
    "# model_name\n",
    "model_name = 't5-small'\n",
    "\n",
    "# traing and validation file path\n",
    "train_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_train_300.json'\n",
    "valid_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_dev_300.json'\n",
    "#train_file = 'data/finetuning/self_ask_train_480.json'\n",
    "#valid_file = 'data/finetuning/self_ask_dev_480.json'\n",
    "\n",
    "previous_checkpoint = \"./model_checkpoints/t5-small_v100_self_ask_300_weights.02-00704.hdf5\"\n",
    "\n",
    "# path and file name for checkpoint\n",
    "checkpoint_dir = '/content/drive/MyDrive/266/compositional_reasoning/model_checkpoints/'\n",
    "checkpoint_filepath = checkpoint_dir + model_name + '_v100_self_ask_300_weights.{epoch:02d}-{batch:00005d}.hdf5'\n",
    "\n",
    "# hyper parameters\n",
    "max_length = 300\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "model_wrapper = finetune_self_ask(model_name, train_file, valid_file, checkpoint_filepath, max_length, batch_size, epochs, previous_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HotPotQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohJ0QQc6LLUD"
   },
   "source": [
    "## Load and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "3HTbEALTLLUE",
    "outputId": "375d1703-24a7-431f-ac11-17e2967a30cd"
   },
   "outputs": [],
   "source": [
    "from data_loaders import load_FinetuningData\n",
    "from training_utils import qa_split, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EklwIHiVLLUF"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_FinetuningData(n_examples=5, split=\"dev\", strategy=\"direct\")\n",
    "questions, answers = qa_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsGEU18qLLUF",
    "outputId": "5665b107-6602-4999-c77a-a14850044f22"
   },
   "outputs": [],
   "source": [
    "print(questions)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZC9JPlSNLLUF",
    "outputId": "e699dadc-3535-4dd4-9f03-197f78ea2cf4"
   },
   "outputs": [],
   "source": [
    "# iterate over question answer pairs and print them\n",
    "for question, answer in zip(questions, answers):\n",
    "    print(question)\n",
    "    print(answer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BiKEcmF1LLUG"
   },
   "outputs": [],
   "source": [
    "# Load self-ask data\n",
    "data = load_FinetuningData(n_examples=5, split=\"dev\", strategy=\"self_ask\")\n",
    "questions, answers = qa_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuOmQ17WLLUG",
    "outputId": "af5f4610-8679-4e65-d1f1-5923efab320d"
   },
   "outputs": [],
   "source": [
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Kk78TidLLUG"
   },
   "source": [
    "## Demo of MultihopQADataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iibm4YK8LLUG",
    "outputId": "7f008e53-b15b-4d94-d392-466504ab1440"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DZbmce7ULLUH",
    "outputId": "dd5c5a88-1d84-4e6b-f724-839b4c40dfc6"
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AVNQGHKmLLUH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_R2UeFOnLLUH",
    "outputId": "d1660227-ac0c-4544-8bab-bbe934932558"
   },
   "outputs": [],
   "source": [
    "# This cell will authenticate you and mount your Drive in the Colab.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311,
     "referenced_widgets": [
      "0304f50d44f144158598804e3671318d",
      "4ae3959fbfc74b99a7ea76d350ba7ff6",
      "3687bdb5005f432a82174c0ad05e6b09",
      "62067fae55c74772a26f8150c1c41661",
      "6ba4de3e80f84cd3b27d709a2f67c395",
      "aca67aa5f66c499da7af7d979ef818c9",
      "249a829372e4402ca5428c6cf570de4f",
      "349561b24a7344de8af29f3009077fb0",
      "cee522e246e04de68ed667a3aab92c64",
      "ec0890e0e25a471dacaec4778565ec86",
      "a187a9f0149040d9a758acfd4972d91a",
      "2a8982922b6141b889ed07a1df582618",
      "e3d18e339e4d4af5971dfe241f013ddd",
      "d469b15fa7ae465e82c11929baf072c3",
      "ec894fc0b7664a6fac216fc961a24f1a",
      "1d057b532c4d402fa0540fa26df2abce",
      "931fb586c3194a61ae1c89576ee0e4b9",
      "67eb9a1604c0465ca0e2f75ca786b1db",
      "71e4cf59d7304072824ef232a0ee7460",
      "4534dbabd5ac4ca6b36b55cd24e1c503",
      "98d51394b4c04b419cda7a26b39772a7",
      "0ca43904714541ee85462930a566f14a",
      "83595f1f310b4e2bb9089297954893d9",
      "b870ce76f0ff4c05bf5fb46479b05d97",
      "ccc5189837f1457790a2634537e2f5cf",
      "dba60e0cfa174ac4b31418f44f0c86b8",
      "fcc76cc4f6c246c18431146e251ac1cb",
      "4bfbedd64e324a5c9c0bd85751c8d8bf",
      "bcb890f8ecb44b5784c224df1cc4ab10",
      "31ea5200727343419cb06033668773c6",
      "8e840a658be74d4ca9373250e8974628",
      "72626abaf3524ef983336b86ffdec4d2",
      "bd1050dc36b442d38e1ce63fe0c5126f"
     ]
    },
    "id": "mkyXQVELLLUH",
    "outputId": "69024f00-c334-4f52-c0aa-d8b3e5b4b52f"
   },
   "outputs": [],
   "source": [
    "# Load the pretrained tensorflow model\n",
    "\n",
    "model_name = 't5-base'\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "t5_model = TFT5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3l2VLGQLLpRP"
   },
   "outputs": [],
   "source": [
    "# richard\n",
    "train_file = 'data/FinetuningData/self_ask_train.json'\n",
    "valid_file = 'data/FinetuningData/self_ask_dev.json'\n",
    "\n",
    "%cd drive/MyDrive/projects/compositional-reasoning-finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uStzs7NIL0yM"
   },
   "outputs": [],
   "source": [
    "n_train_pairs = 154876\n",
    "n_valid_pairs = 12576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QgkJG561LLUI"
   },
   "outputs": [],
   "source": [
    "train_file = 'drive/MyDrive/266/data/self_ask_train.json'\n",
    "valid_file = 'drive/MyDrive/266/data/self_ask_dev.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9sICT5VLLUI"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f_train = open('drive/MyDrive/266/data/self_ask_train.json')\n",
    "f_valid = open('drive/MyDrive/266/data/self_ask_dev.json')\n",
    "\n",
    "js_train = json.load(f_train)\n",
    "js_valid = json.load(f_valid)\n",
    "\n",
    "# Close JSON file\n",
    "f_train.close()\n",
    "f_valid.close()\n",
    "\n",
    "n_train_pairs = len(js_train) #154876\n",
    "n_valid_pairs = len(js_valid) #12576\n",
    "\n",
    "del js_train\n",
    "del js_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJQ2MhuiLLUI"
   },
   "outputs": [],
   "source": [
    "# Create the data generators for train and validation data, tensorflow version\n",
    "from training_utils import MultihopQADataGenerator\n",
    "\n",
    "max_length = 32\n",
    "max_length = 512\n",
    "batch_size = 16\n",
    "\n",
    "train_data_generator = MultihopQADataGenerator(\n",
    "    tokenizer=t5_tokenizer,\n",
    "    model=t5_model,\n",
    "    n_examples=n_train_pairs,\n",
    "    data_filename=train_file,\n",
    "    max_length=max_length,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "valid_data_generator = MultihopQADataGenerator(\n",
    "    tokenizer=t5_tokenizer,\n",
    "    model=t5_model,\n",
    "    n_examples=n_valid_pairs,\n",
    "    data_filename=valid_file,\n",
    "    max_length=max_length,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUOsacBcLLUI"
   },
   "outputs": [],
   "source": [
    "def build_t5_training_wrapper_model(t5_model, max_length):\n",
    "    input_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = layers.Input(shape=(max_length), dtype=tf.int32, name='attention_mask')\n",
    "    decoder_input_ids = layers.Input(shape=(max_length), dtype=tf.int32, name='labels')\n",
    "\n",
    "    t5_logits = t5_model(input_ids, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids)[0]\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[input_ids, attention_mask, decoder_input_ids],\n",
    "                                  outputs=[t5_logits])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cglZF2rLLUJ"
   },
   "outputs": [],
   "source": [
    "model_wrapper = build_t5_training_wrapper_model(t5_model, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6DNNn9kLLUJ"
   },
   "outputs": [],
   "source": [
    "# As in the first notebook, we should add a model checkpoint callback to save\n",
    "# the trained model weights after each epoch. Edit the filepath to where\n",
    "# you want to save the weights in your own Drive\n",
    "\n",
    "# checkpoint_dir = 'drive/MyDrive/266/data/self_ask/model_checkpoints/'\n",
    "checkpoint_dir = 'drive/MyDrive/projects/compositional-reasoning-finetuning/checkpoints/t5-base-self-ask/' # richard\n",
    "checkpoint_filepath = checkpoint_dir + 't5_direct_weights.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "eLcgtXD5LLUJ",
    "outputId": "7d943358-84d0-4bef-d3d3-f62f3f8e8588"
   },
   "outputs": [],
   "source": [
    "# Now call .fit on the model_wrapper, passing in the data generators and the\n",
    "# model checkpoint callback\n",
    "\n",
    "model_wrapper.fit(train_data_generator,\n",
    "                  validation_data=valid_data_generator,\n",
    "                  epochs=1,\n",
    "                  callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toPdU6Z8Z-sr"
   },
   "source": [
    "## Standardized function call for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpV_ApGFQxSd",
    "outputId": "a6589042-eaad-4c9a-c34c-c9464dfa684d"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yjbi4156StfI",
    "outputId": "f96114a5-d5c0-4d2a-bd3e-b7596178c111"
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2Q2daEoQq1e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4v8wQbPLOF5Q",
    "outputId": "04c10453-b4c5-49e5-9770-e08b3a4bb1f7"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJaLXmR0Oder",
    "outputId": "77dd22eb-4b70-44c8-f087-f61117d27054"
   },
   "outputs": [],
   "source": [
    "%cd drive/MyDrive/266/compositional_reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "CyFSd1hHZ-sr",
    "outputId": "42ea4bd8-020f-4928-9900-a0782397bee2"
   },
   "outputs": [],
   "source": [
    "from training_utils import finetune_self_ask\n",
    "import json\n",
    "\n",
    "# model_name\n",
    "model_name = 't5-base'\n",
    "\n",
    "# traing and validation file path\n",
    "#train_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_train.json'\n",
    "#valid_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_dev.json'\n",
    "train_file = 'data/finetuning/self_ask_train.json'\n",
    "valid_file = 'data/finetuning/self_ask_dev.json'\n",
    "\n",
    "# path and file name for checkpoint\n",
    "checkpoint_dir = 'model_checkpoints/'\n",
    "checkpoint_filepath = checkpoint_dir + model_name + '_self_ask_weights.{epoch:02d}-{batch:00005d}.hdf5'\n",
    "\n",
    "# hyper parameters\n",
    "max_length = 600\n",
    "batch_size = 16\n",
    "epochs = 2\n",
    "\n",
    "model_wrapper = finetune_self_ask(model_name, train_file, valid_file, checkpoint_filepath, max_length, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function call to filter json by token size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd drive/MyDrive/266/compositional_reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_train.json'\n",
    "valid_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_dev.json'\n",
    "token_size = 470"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_token_size(train_file, valid_file, token_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previously saved checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_utils import finetune_self_ask\n",
    "import json\n",
    "\n",
    "# model_name\n",
    "model_name = 't5-small'\n",
    "\n",
    "# traing and validation file path\n",
    "train_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_train_300.json'\n",
    "valid_file = '/content/drive/MyDrive/266/compositional_reasoning/data/finetuning/self_ask_dev_300.json'\n",
    "#train_file = 'data/finetuning/self_ask_train_480.json'\n",
    "#valid_file = 'data/finetuning/self_ask_dev_480.json'\n",
    "\n",
    "previous_checkpoint = \"./model_checkpoints/t5-small_v100_self_ask_300_weights.02-00704.hdf5\"\n",
    "\n",
    "# path and file name for checkpoint\n",
    "checkpoint_dir = '/content/drive/MyDrive/266/compositional_reasoning/model_checkpoints/'\n",
    "checkpoint_filepath = checkpoint_dir + model_name + '_v100_self_ask_300_weights.{epoch:02d}-{batch:00005d}.hdf5'\n",
    "\n",
    "# hyper parameters\n",
    "max_length = 300\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "model_wrapper = finetune_self_ask(model_name, train_file, valid_file, checkpoint_filepath, max_length, batch_size, epochs, previous_checkpoint)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
