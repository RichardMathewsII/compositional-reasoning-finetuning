{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10760,"status":"ok","timestamp":1701998643429,"user":{"displayName":"Adam Weinberger","userId":"08337288854678718340"},"user_tz":300},"id":"Iibm4YK8LLUG","outputId":"075fd084-21ab-4424-9348-c67d07934dac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8484,"status":"ok","timestamp":1701998651910,"user":{"displayName":"Adam Weinberger","userId":"08337288854678718340"},"user_tz":300},"id":"DZbmce7ULLUH","outputId":"40761774-ae93-4be5-b002-13baf0be079e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m1.2/1.3 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}],"source":["!pip install sentencepiece"]},{"cell_type":"code","source":["!pip install loguru"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-3lAug9geBf","executionInfo":{"status":"ok","timestamp":1701998662391,"user_tz":300,"elapsed":10492,"user":{"displayName":"Adam Weinberger","userId":"08337288854678718340"}},"outputId":"2cb438a0-4a4e-4c4e-eb4d-54e620b92f2d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting loguru\n","  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: loguru\n","Successfully installed loguru-0.7.2\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15134,"status":"ok","timestamp":1701998677519,"user":{"displayName":"Adam Weinberger","userId":"08337288854678718340"},"user_tz":300},"id":"_R2UeFOnLLUH","outputId":"d17c8bbf-bee4-42f0-e57f-8433c9fd9cbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# This cell will authenticate you and mount your Drive in the Colab.\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":312,"status":"ok","timestamp":1701981306054,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":360},"id":"wh_iGojfZ5b2","outputId":"5b5a6289-7ed7-477d-e4b8-a56c12451dd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/projects/compositional-reasoning-finetuning\n"]}],"source":["# %cd drive/MyDrive/projects/compositional-reasoning-finetuning\n","%cd drive/MyDrive/projects/compositional-reasoning-finetuning"]},{"cell_type":"markdown","source":["## Chunk training data"],"metadata":{"id":"1Yt85iSfL5z6"}},{"cell_type":"code","source":["import json\n","\n","model = \"self_ask_train-answer_first=False-random_facts=True\"\n","in_file = f\"data/FinetuningData/{model}.json\"\n","out_dir = f\"data/FinetuningData/{model}/\"\n","with open(in_file, \"r\") as f:\n","  train = json.load(f)\n","\n","chunks = 15\n","chunk_size = len(train) // chunks\n","start = 0\n","end = chunk_size\n","chunk_num = 1\n","while end <= len(train):\n","  with open(out_dir+f\"chunk-{chunk_num}.json\", \"w\") as f:\n","    json.dump(train[start: end], f)\n","  print(start, end)\n","  start += chunk_size\n","  end += chunk_size\n","  chunk_num+=1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CM-CbbgtFbe_","executionInfo":{"status":"ok","timestamp":1701976045426,"user_tz":360,"elapsed":8402,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"}},"outputId":"97f74b32-d571-4e40-ca21-abf488d30f91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 10325\n","10325 20650\n","20650 30975\n","30975 41300\n","41300 51625\n","51625 61950\n","61950 72275\n","72275 82600\n","82600 92925\n","92925 103250\n","103250 113575\n","113575 123900\n","123900 134225\n","134225 144550\n","144550 154875\n"]}]},{"cell_type":"markdown","metadata":{"id":"MdvQ-88ifhJS"},"source":["## Self-Ask Finetuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h3niD4rSbFtO"},"outputs":[],"source":["from training_utils import finetune_self_ask"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":944369,"status":"ok","timestamp":1701982259625,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"},"user_tz":360},"id":"XbAxM0SjfhJS","outputId":"d9e5e070-7679-4b1a-9cf8-9cf7a63489d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["13\n"]},{"output_type":"stream","name":"stderr","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n","\n","All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["322/322 [==============================] - 304s 851ms/step - loss: 0.1875 - accuracy: 0.9726 - val_loss: 0.0400 - val_accuracy: 0.9918\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["14\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n","\n","All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["322/322 [==============================] - 302s 848ms/step - loss: 0.1769 - accuracy: 0.9734 - val_loss: 0.0406 - val_accuracy: 0.9917\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["15\n"]},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n","\n","All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["322/322 [==============================] - 312s 877ms/step - loss: 0.1811 - accuracy: 0.9730 - val_loss: 0.0406 - val_accuracy: 0.9918\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["# model_name\n","huggingface_model_name = 't5-small'\n","model = \"self_ask_train-answer_first=False-random_facts=True\"\n","\n","# traing and validation file path\n","chunks = 15  # should match number of chunks in data directory\n","chunk_start = 13  # if you need to start at a different chunk number, change this\n","valid_file = 'data/FinetuningData/self_ask_dev-answer_first=False-random_facts=True.json'\n","\n","checkpoint_dir = f'checkpoints/{model}/'\n","# prev_checkpoint = \"\"\n","prev_checkpoint = f\"{checkpoint_dir}/weights-{chunk_start-1}.hdf5\"\n","\n","# hyper parameters\n","max_length = 300\n","batch_size = 32\n","epochs = 1\n","\n","for chunk in range(chunk_start, chunks+1):\n","  print(chunk)\n","  train_file = f'data/FinetuningData/self_ask_train-answer_first=False-random_facts=True/chunk-{chunk}.json'\n","\n","  # path and file name for checkpoint\n","  checkpoint_filepath = checkpoint_dir + f'weights-{chunk}' + '.{epoch:02d}-{batch:00005d}.hdf5'\n","\n","  model_wrapper = finetune_self_ask(\n","      huggingface_model_name,\n","      train_file,\n","      valid_file,\n","      checkpoint_filepath,\n","      max_length,\n","      batch_size,\n","      epochs,\n","      prev_checkpoint)\n","\n","  prev_checkpoint = f\"{checkpoint_dir}/weights-{chunk}.hdf5\"\n","  model_wrapper.save(prev_checkpoint, save_format=\"hdf5\")\n","  del model_wrapper"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xlr3uN0AYYBS","colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"status":"error","timestamp":1701975873653,"user_tz":360,"elapsed":403,"user":{"displayName":"Richard Mathews","userId":"15085444626849988348"}},"outputId":"aea4953f-9d5d-4cf4-97c7-21747146373e"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-ec0db6ffe2b0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"models/{model}.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model_wrapper' is not defined"]}],"source":["model_wrapper.save(f\"models/{model}.h5\", save_format=\"h5\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}